{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "#from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/denis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/opt/anaconda3/envs/ds_env/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "snowball = SnowballStemmer(language=\"russian\")\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "count = pickle.load(open(\"NLP_model/count.pkl\", 'rb'))\n",
    "feature_names = count.get_feature_names_out()\n",
    "tfidf_transformer = pickle.load(open(\"NLP_model/tfidf_transformer.pkl\", 'rb'))\n",
    "\n",
    "logreg = pickle.load(open(\"NLP_model/model_logreg.pkl\", 'rb'))\n",
    "SVC_model = pickle.load(open(\"NLP_model/model_svc.pkl\", 'rb'))\n",
    "LinearSVC_model = pickle.load(open(\"NLP_model/model_linearSVC.pkl\", 'rb'))\n",
    "GradBst = pickle.load(open(\"NLP_model/model_RandForest.pkl\", 'rb'))\n",
    "RandForest = pickle.load(open(\"NLP_model/model_GradBst.pkl\", 'rb'))\n",
    "Stacking_models = pickle.load(open(\"NLP_model/model_Stacking_models.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tfidf(phrase):\n",
    "    # токенизация\n",
    "    phrase_tok = tokenizer.tokenize(phrase.lower())\n",
    "    # препроцессинг фразы\n",
    "    phrase_lem_stem = []\n",
    "    for w in phrase_tok:\n",
    "        if w not in stop_words and w not in special_char:\n",
    "            # лемматизация и стемминг русских слов\n",
    "            word_lem_stem_rus = snowball.stem(morph.normal_forms(w)[0])\n",
    "            # лемматизация и стемминг английских слов\n",
    "            word_lem_stem_rus_eng = ps.stem((lemmatizer.lemmatize(word_lem_stem_rus)))\n",
    "            phrase_lem_stem.append(word_lem_stem_rus_eng)\n",
    "            string = (' '.join(phrase_lem_stem))\n",
    "    phrase_preprocessed = [string]\n",
    "    #using the count vectorizer\n",
    "    phrase_words_count = count.transform(phrase_preprocessed)\n",
    "    #tfidf\n",
    "    phrase_words_tfidf_short = tfidf_transformer.transform(phrase_words_count)\n",
    "    phrase_words_tfidf = pd.DataFrame(phrase_words_tfidf_short.T.todense(), index=feature_names, columns=[0])\n",
    "    return phrase_words_tfidf.T\n",
    "\n",
    "def predict_logreg(phrase):\n",
    "    phrase_tfidf = string_to_tfidf(phrase) \n",
    "    if logreg.predict(phrase_tfidf) > 0.5:\n",
    "        is_toxic = \"The comment is toxic\"\n",
    "    else:\n",
    "        is_toxic = \"The comment isn't toxic\"\n",
    "    return is_toxic\n",
    "\n",
    "def predict_svc(phrase):\n",
    "    phrase_tfidf = string_to_tfidf(phrase) \n",
    "    if SVC_model.predict(phrase_tfidf) > 0.5:\n",
    "        is_toxic = \"The comment is toxic\"\n",
    "    else:\n",
    "        is_toxic = \"The comment isn't toxic\"\n",
    "    return is_toxic\n",
    "\n",
    "def predict_linearSVC(phrase):\n",
    "    phrase_tfidf = string_to_tfidf(phrase) \n",
    "    if LinearSVC_model.predict(phrase_tfidf) > 0.5:\n",
    "        is_toxic = \"The comment is toxic\"\n",
    "    else:\n",
    "        is_toxic = \"The comment isn't toxic\"\n",
    "    return is_toxic\n",
    "\n",
    "def predict_GradBst(phrase):\n",
    "    phrase_tfidf = string_to_tfidf(phrase) \n",
    "    if GradBst.predict(phrase_tfidf) > 0.5:\n",
    "        is_toxic = \"The comment is toxic\"\n",
    "    else:\n",
    "        is_toxic = \"The comment isn't toxic\"\n",
    "    return is_toxic\n",
    "\n",
    "def predict_RandForest(phrase):\n",
    "    phrase_tfidf = string_to_tfidf(phrase) \n",
    "    if RandForest.predict(phrase_tfidf) > 0.5:\n",
    "        is_toxic = \"The comment is toxic\"\n",
    "    else:\n",
    "        is_toxic = \"The comment isn't toxic\"\n",
    "    return is_toxic\n",
    "\n",
    "def predict_Stacking_models(phrase):\n",
    "    phrase_tfidf = string_to_tfidf(phrase) \n",
    "    if Stacking_models.predict(phrase_tfidf) > 0.5:\n",
    "        is_toxic = \"The comment is toxic\"\n",
    "    else:\n",
    "        is_toxic = \"The comment isn't toxic\"\n",
    "    return is_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фраза: Привет. Как дела?\n",
      "\n",
      "Классификация с помощью логистической регрессии:\n",
      "The comment isn't toxic\n",
      "\n",
      "Классификация с помощью SVC:\n",
      "The comment is toxic\n",
      "\n",
      "Классификация с помощью LinearSVC:\n",
      "The comment is toxic\n",
      "\n",
      "Классификация с помощью градиентного бустинга:\n",
      "The comment is toxic\n",
      "\n",
      "Классификация с помощью случайного леса:\n",
      "The comment isn't toxic\n",
      "\n",
      "Классификация с помощью стэкинга:\n",
      "The comment isn't toxic\n"
     ]
    }
   ],
   "source": [
    "phrase = str(input())\n",
    "print(f\"Фраза: {phrase}\")\n",
    "print(\"\\nКлассификация с помощью логистической регрессии:\")\n",
    "print(predict_logreg(phrase))\n",
    "print(\"\\nКлассификация с помощью SVC:\")\n",
    "print(predict_svc(phrase))\n",
    "print(\"\\nКлассификация с помощью LinearSVC:\")\n",
    "print(predict_linearSVC(phrase))\n",
    "print(\"\\nКлассификация с помощью градиентного бустинга:\")\n",
    "print(predict_RandForest(phrase))\n",
    "print(\"\\nКлассификация с помощью случайного леса:\")\n",
    "print(predict_GradBst(phrase))\n",
    "print(\"\\nКлассификация с помощью стэкинга:\")\n",
    "print(predict_Stacking_models(phrase))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412736b7ad9a6211ebe07fddd452488530ba48e4d95dcf46d993658ed665f40c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
