{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV, LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39073, 14), (9769, 14), (39073,), (9769,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разбиваем выборку на обучающую и тестовую с помьщью функции train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=RANDOM_STATE)  # добавляем random stete для повторяемости результата\n",
    "\n",
    "# Выводим размеры тестовой и обучающей выборок и целевой переменной\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучите стандартную регрессию, а также Ridge и Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "# обучаем модель на обучающей выборке\n",
    "linear.fit(X_train, y_train)\n",
    "# рассчет R2 для тестовой выборки\n",
    "Linear_r2 = r2_score(y_test, linear.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия с регуляризацией L2 (Ridge) с параметрами по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "# обучаем модель на обучающей выборке\n",
    "ridge.fit(X_train, y_train)\n",
    "# рассчет R2 для тестовой выборки\n",
    "Ridge_r2 = r2_score(y_test, ridge.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия с регуляризацией L1 (Lasso) с параметрами по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "# обучаем модель на обучающей выборке\n",
    "lasso.fit(X_train, y_train)\n",
    "# рассчет R2 для тестовой выборки\n",
    "Lasso_r2 = r2_score(y_test, lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод R2 (коэффициентов детерминации) для линейной регрессии, Ridge и Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression: 0.668759\n",
      "R2 Ridge regression:  0.666222\n",
      "R2 Lasso regression:  0.667145\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 Linear regression: {Linear_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression:  {Ridge_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression:  {Lasso_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 для линейной регрессии, Ridge и Lasso с параметрами по умолчанию сопоставимы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Для Ridge и Lasso подберите коэффициент регуляризации (используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ridge(alpha=1e-05), Lasso(alpha=1e-05))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'alpha':np.logspace(-5, 5, 11)}\n",
    "\n",
    "# подбираем коэффициент регуляризации для Ridge с помощью GridSearchCV\n",
    "Ridge_GSCV = GridSearchCV(Ridge(), parameters)\n",
    "Ridge_GSCV.fit(X_train, y_train)\n",
    "\n",
    "# подбираем коэффициент регуляризации для Lasso с помощью GridSearchCV\n",
    "Lasso_GSCV = GridSearchCV(Lasso(), parameters)\n",
    "Lasso_GSCV.fit(X_train, y_train)\n",
    "\n",
    "# Вывод лучших коэффициентов регуляризации\n",
    "Ridge_GSCV.best_estimator_, Lasso_GSCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Ridge regression with GridSearchCV: 0.668759\n",
      "R2 Lasso regression with GridSearchCV: 0.668760\n"
     ]
    }
   ],
   "source": [
    "# Ridge регрессия с лучшим коэффициентом регуляризации\n",
    "Ridge_GSCV_best = Ridge_GSCV.best_estimator_\n",
    "# Рассчет R2 для тестовой выборки\n",
    "Ridge_GSCV_r2 = r2_score(y_test, Ridge_GSCV_best.predict(X_test))\n",
    "\n",
    "# Lasso регрессия с лучшим коэффициентом регуляризации\n",
    "Lasso_GSCV_best = Lasso_GSCV.best_estimator_\n",
    "# Рассчет R2 для тестовой выборки\n",
    "Lasso_GSCV_r2 = r2_score(y_test, Lasso_GSCV_best.predict(X_test))\n",
    "\n",
    "print(f\"R2 Ridge regression with GridSearchCV: {Ridge_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with GridSearchCV: {Lasso_GSCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.01\n"
     ]
    }
   ],
   "source": [
    "# подбираем коэффициент регуляризации для Ridge с помощью RidgeCV\n",
    "RidCV = RidgeCV(alphas = np.logspace(-5, 5, 11))\n",
    "RidCV.fit(X_train, y_train)\n",
    "print(f\"alpha={RidCV.alpha_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе теста определено, что предсказание происходит не по лучшей модели, а по какой-то средней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Ridge regression with RidgeCV: 0.668751\n"
     ]
    }
   ],
   "source": [
    "# Обучим модель с подобранным коэффициентом регуляризации с помощью RidgeCV\n",
    "RidCV_best = Ridge(alpha=RidCV.alpha_)\n",
    "RidCV_best.fit(X_train, y_train)\n",
    "# Рассчет R2 для тестовой выборки\n",
    "Ridge_RidCV_r2 = r2_score(y_test, RidCV_best.predict(X_test))\n",
    "print(f\"R2 Ridge regression with RidgeCV: {Ridge_RidCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.00001\n"
     ]
    }
   ],
   "source": [
    "# подбираем коэффициент регуляризации для Lasso с помощью LassoCV\n",
    "LassCV = LassoCV(alphas = np.logspace(-5, 5, 11))\n",
    "LassCV.fit(X_train, y_train)\n",
    "print(f\"alpha={LassCV.alpha_:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе теста определено, что предсказание происходит по лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Lasso regression with LassoCV: 0.668760\n"
     ]
    }
   ],
   "source": [
    "# Расчет R2 для тестовой выборки\n",
    "Lasso_LassCV_r2 = r2_score(y_test, LassCV.predict(X_test))\n",
    "print(f\"R2 Lasso regression with LassoCV: {Lasso_LassCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression:                 0.668759\n",
      "\n",
      "R2 Ridge regression Default:          0.666222\n",
      "R2 Ridge regression withGridSearchCV: 0.668759\n",
      "R2 Ridge regression withRidgeCV:      0.668751\n",
      "\n",
      "R2 Lasso regression Default:          0.667145\n",
      "R2 Lasso regression withGridSearchCV: 0.668760\n",
      "R2 Lasso regression withLassoCV:      0.668760\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 Linear regression:                 {Linear_r2:.6f}\")\n",
    "print()\n",
    "print(f\"R2 Ridge regression Default:          {Ridge_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression withGridSearchCV: {Ridge_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression withRidgeCV:      {Ridge_RidCV_r2:.6f}\")\n",
    "print()\n",
    "print(f\"R2 Lasso regression Default:          {Lasso_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression withGridSearchCV: {Lasso_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression withLassoCV:      {Lasso_LassCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:  \n",
    "- R2 для Ridge с подобранными коэффициентами регуляризации с помощью GridSearchCV и RidgeCV незначительно различаются (коэффициенты отличаются);  \n",
    "- R2 для Lasso с подобранными коэффициентами регуляризации с помощью GridSearchCV и LassoCV не различаются (коэффициенты одинаковы);\n",
    "- R2 и для Ridge и для Lasso с подобранными коэффициентами регуляризации несколько лучше, чем для Ridge и для Lasso с параметрами по умолчанию (для данных выборок) - на 0,25% для Ridge  и на 0,15% для Lasso  \n",
    "- R2 и для Ridge и для Lasso с подобранными коэффициентами регуляризации практачески равен R2 для линейной регрессии (аналитический метод)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression with StandardScaler: 0.668759\n"
     ]
    }
   ],
   "source": [
    "# Линейная регрессия на масштабированных данных (StandardScaler)\n",
    "Linear_StScal = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", LinearRegression())])\n",
    "Linear_StScal.fit(X_train, y_train)\n",
    "\n",
    "# Расчет R2 для тестовой выборки\n",
    "Linear_StScal_r2 = r2_score(y_test, Linear_StScal.predict(X_test))\n",
    "print(f\"R2 Linear regression with StandardScaler: {Linear_StScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Ridge regression with StandardScaler: 0.668462\n"
     ]
    }
   ],
   "source": [
    "# Ridge регрессия на масштабированных данных (StandardScaler)\n",
    "Ridge_StScal = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", Ridge())])\n",
    "Ridge_StScal.fit(X_train, y_train)\n",
    "\n",
    "# Расчет R2 для тестовой выборки\n",
    "Ridge_StScal_r2 = r2_score(y_test, Ridge_StScal.predict(X_test))\n",
    "print(f\"R2 Ridge regression with StandardScaler: {Ridge_StScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Lasso regression with StandardScaler: 0.623943\n"
     ]
    }
   ],
   "source": [
    "# Lasso регрессия на масштабированных данных (StandardScaler)\n",
    "Lasso_StScal = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", Lasso())])\n",
    "Lasso_StScal.fit(X_train, y_train)\n",
    "\n",
    "# Расчет R2 для тестовой выборки\n",
    "Lasso_StScal_r2 = r2_score(y_test, Lasso_StScal.predict(X_test))\n",
    "print(f\"R2 Lasso regression with StandardScaler: {Lasso_StScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression with MinMaxScaler: 0.668759\n"
     ]
    }
   ],
   "source": [
    "# Линейная регрессия на масштабированных данных (MinMaxScaler)\n",
    "Linear_MinMaxScal = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", LinearRegression())])\n",
    "Linear_MinMaxScal.fit(X_train, y_train)\n",
    "\n",
    "# Расчет R2 для тестовой выборки\n",
    "Linear_MinMaxScal_r2 = r2_score(y_test, Linear_MinMaxScal.predict(X_test))\n",
    "print(f\"R2 Linear regression with MinMaxScaler: {Linear_MinMaxScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Ridge regression with MinMaxScaler: 0.676410\n"
     ]
    }
   ],
   "source": [
    "# Ridge регрессия на масштабированных данных (MinMaxScaler)\n",
    "Ridge_MinMaxScal = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", Ridge())])\n",
    "Ridge_MinMaxScal.fit(X_train, y_train)\n",
    "\n",
    "# Расчет R2 для тестовой выборки\n",
    "Ridge_MinMaxScal_r2 = r2_score(y_test, Ridge_MinMaxScal.predict(X_test))\n",
    "print(f\"R2 Ridge regression with MinMaxScaler: {Ridge_MinMaxScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Lasso regression with MinMaxScaler: 0.257392\n"
     ]
    }
   ],
   "source": [
    "# Lasso регрессия на масштабированных данных (MinMaxScaler)\n",
    "Lasso_MinMaxScal = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", Lasso())])\n",
    "Lasso_MinMaxScal.fit(X_train, y_train)\n",
    "\n",
    "# Расчет R2 для тестовой выборки\n",
    "Lasso_MinMaxScal_r2 = r2_score(y_test, Lasso_MinMaxScal.predict(X_test))\n",
    "print(f\"R2 Lasso regression with MinMaxScaler: {Lasso_MinMaxScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression:                     0.668759\n",
      "R2 Linear regression with StandardScaler: 0.668759\n",
      "R2 Linear regression with MinMaxScaler:   0.668759\n",
      "\n",
      "R2 Ridge regression Default:              0.666222\n",
      "R2 Ridge regression with GridSearchCV:    0.668759\n",
      "R2 Ridge regression with RidgeCV:         0.668751\n",
      "R2 Ridge regression with StandardScaler:  0.668462\n",
      "R2 Ridge regression with MinMaxScaler:    0.676410\n",
      "\n",
      "R2 Lasso regression Default:              0.667145\n",
      "R2 Lasso regression with GridSearchCV:    0.668760\n",
      "R2 Lasso regression with LassoCV:         0.668760\n",
      "R2 Lasso regression with StandardScaler:  0.623943\n",
      "R2 Lasso regression with MinMaxScaler:    0.257392\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 Linear regression:                     {Linear_r2:.6f}\")\n",
    "print(f\"R2 Linear regression with StandardScaler: {Linear_StScal_r2:.6f}\")\n",
    "print(f\"R2 Linear regression with MinMaxScaler:   {Linear_MinMaxScal_r2:.6f}\")\n",
    "print()\n",
    "print(f\"R2 Ridge regression Default:              {Ridge_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with GridSearchCV:    {Ridge_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with RidgeCV:         {Ridge_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with StandardScaler:  {Ridge_StScal_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with MinMaxScaler:    {Ridge_MinMaxScal_r2:.6f}\")\n",
    "print()\n",
    "print(f\"R2 Lasso regression Default:              {Lasso_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with GridSearchCV:    {Lasso_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with LassoCV:         {Lasso_LassCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with StandardScaler:  {Lasso_StScal_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with MinMaxScaler:    {Lasso_MinMaxScal_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- на линейной регрессии масштабирование не сказалось;\n",
    "- для Ridge регрессии с масштабированием результат лучше, чем без масштабирования, особенно с помощью MinMaxScaler (R2 выше почти на 0,01);\n",
    "- для Lasso регрессии с масштабированием результат оказался гораздо хуже, чем без масштабирования, особенно с помощью MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор коэффициентов регуляризации для Ridge и Lasso на масштабированных данных с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подобранный с помощью GridSearchCV коэффициент регулярязации для Ridge на масштабированных данных StandardScaler: 1.0\n",
      "Подобранный с помощью GridSearchCV коэффициент регулярязации для Ridge на масштабированных данных MinMaxScaler:   0.1\n",
      "Подобранный с помощью GridSearchCV коэффициент регулярязации для Lasso на масштабированных данных StandardScaler: 0.00001\n",
      "Подобранный с помощью GridSearchCV коэффициент регулярязации для Lasso на масштабированных данных MinMaxScaler:   0.00001\n",
      "\n",
      "R2 Ridge regression with StandardScaler & GridSearchCV: 0.668462\n",
      "R2 Ridge regression with MinMaxScaler   & GridSearchCV: 0.670031\n",
      "R2 Lasso regression with StandardScaler & GridSearchCV: 0.668759\n",
      "R2 Lasso regression with MinMaxScaler   & GridSearchCV: 0.668761\n"
     ]
    }
   ],
   "source": [
    "parameters = {'regression__alpha':np.logspace(-5, 5, 11)}\n",
    "\n",
    "\n",
    "# создаем pipline (StandardScaler и Ridge регрессия)\n",
    "Ridge_StScal = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", Ridge())])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью GridSearchCV\n",
    "Ridge_StScal_GSCV = GridSearchCV(Ridge_StScal, parameters)\n",
    "Ridge_StScal_GSCV.fit(X_train, y_train)\n",
    "# расчет R2 на тестовых данных\n",
    "Ridge_StScal_GSCV_r2 = r2_score(y_test, Ridge_StScal_GSCV.predict(X_test))\n",
    "\n",
    "\n",
    "# создаем pipline (MinMaxScaler и Ridge регрессия)\n",
    "Ridge_MinMaxScal = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", Ridge())])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью GridSearchCV\n",
    "Ridge_MinMaxScal_GSCV = GridSearchCV(Ridge_MinMaxScal, parameters)\n",
    "Ridge_MinMaxScal_GSCV.fit(X_train, y_train)\n",
    "# расчет R2 на тестовых данных\n",
    "Ridge_MinMaxScal_GSCV_r2 = r2_score(y_test, Ridge_MinMaxScal_GSCV.predict(X_test))\n",
    "\n",
    "\n",
    "# создаем pipline (StandardScaler и Lasso регрессия)\n",
    "Lasso_StScal = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", Lasso())])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью GridSearchCV\n",
    "Lasso_StScal_GSCV = GridSearchCV(Lasso_StScal, parameters)\n",
    "Lasso_StScal_GSCV.fit(X_train, y_train)\n",
    "# расчет R2 на тестовых данных\n",
    "Lasso_StScal_GSCV_r2 = r2_score(y_test, Lasso_StScal_GSCV.predict(X_test))\n",
    "\n",
    "\n",
    "# создаем pipline (MinMaxScaler и Lasso регрессия)\n",
    "Lasso_MinMaxScal = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", Lasso())])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью GridSearchCV\n",
    "Lasso_MinMaxScal_GSCV = GridSearchCV(Lasso_MinMaxScal, parameters)\n",
    "Lasso_MinMaxScal_GSCV.fit(X_train, y_train)\n",
    "# расчет R2 на тестовых данных\n",
    "Lasso_MinMaxScal_GSCV_r2 = r2_score(y_test, Lasso_MinMaxScal_GSCV.predict(X_test))\n",
    "\n",
    "\n",
    "# Вывод лучших коэффициентов регуляризации\n",
    "print(f\"Подобранный с помощью GridSearchCV коэффициент регулярязации для Ridge на масштабированных данных StandardScaler: {Ridge_StScal_GSCV.best_params_.get('regression__alpha')}\")\n",
    "print(f\"Подобранный с помощью GridSearchCV коэффициент регулярязации для Ridge на масштабированных данных MinMaxScaler:   {Ridge_MinMaxScal_GSCV.best_params_.get('regression__alpha')}\")\n",
    "print(f\"Подобранный с помощью GridSearchCV коэффициент регулярязации для Lasso на масштабированных данных StandardScaler: {Lasso_StScal_GSCV.best_params_.get('regression__alpha'):.5f}\")\n",
    "print(f\"Подобранный с помощью GridSearchCV коэффициент регулярязации для Lasso на масштабированных данных MinMaxScaler:   {Lasso_MinMaxScal_GSCV.best_params_.get('regression__alpha'):.5f}\")\n",
    "print()\n",
    "\n",
    "# Вывод R2\n",
    "print(f\"R2 Ridge regression with StandardScaler & GridSearchCV: {Ridge_StScal_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with MinMaxScaler   & GridSearchCV: {Ridge_MinMaxScal_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with StandardScaler & GridSearchCV: {Lasso_StScal_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with MinMaxScaler   & GridSearchCV: {Lasso_MinMaxScal_GSCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор коэффициентов регуляризации для Ridge на масштабированных данных с помощью RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Опытным путем определено, что RidgeCV на масштабированных данных с помощью StandardScaler подобран коэффициент регуляризации 10\n",
      "Опытным путем определено, что RidgeCV на масштабированных данных с помощью MinMaxScaler подобран коэффициент регуляризации  0.1\n",
      "\n",
      "R2 Ridge regression with StandardScaler & RidgeCV: 0.665968\n",
      "R2 Ridge regression with MinMaxScaler   & RidgeCV: 0.670031\n"
     ]
    }
   ],
   "source": [
    "# создаем pipline (StandardScaler и RidgeCV регрессия)\n",
    "Ridge_StScal_RidCV = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", RidgeCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью RidgeCV\n",
    "Ridge_StScal_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Ridge_StScal_RidCV_r2 = r2_score(y_test, Ridge_StScal_RidCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (MinMaxScaler и RidgeCV регрессия)\n",
    "Ridge_MinMaxScal_RidCV = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", RidgeCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью RidgeCV\n",
    "Ridge_MinMaxScal_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Ridge_MinMaxScal_RidCV_r2 = r2_score(y_test, Ridge_MinMaxScal_RidCV.predict(X_test))\n",
    "\n",
    "# выводим коэффициенты регуляризации и R2\n",
    "print(\"Опытным путем определено, что RidgeCV на масштабированных данных с помощью StandardScaler подобран коэффициент регуляризации 10\")\n",
    "print(\"Опытным путем определено, что RidgeCV на масштабированных данных с помощью MinMaxScaler подобран коэффициент регуляризации  0.1\")\n",
    "print()\n",
    "print(f\"R2 Ridge regression with StandardScaler & RidgeCV: {Ridge_StScal_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with MinMaxScaler   & RidgeCV: {Ridge_MinMaxScal_RidCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор коэффициентов регуляризации для Lasso на масштабированных данных с помощью LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Опытным путем определено, что LassoCV на масштабированных данных с помощью StandardScaler подобран коэффициент регуляризации 0.00001\n",
      "Опытным путем определено, что LassoCV на масштабированных данных с помощью MinMaxScaler подобран коэффициент регуляризации   0.00001\n",
      "\n",
      "R2 Lasso regression with StandardScaler & LassoCV: 0.668759\n",
      "R2 Lasso regression with MinMaxScaler   & LassoCV: 0.668761\n"
     ]
    }
   ],
   "source": [
    "# создаем pipline (StandardScaler и LassoCV регрессия)\n",
    "Lasso_StScal_LassCV = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"regression\", LassoCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью LassoCV\n",
    "Lasso_StScal_LassCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Lasso_StScal_LassCV_r2 = r2_score(y_test, Lasso_StScal_LassCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (MinMaxScaler и LassoCV регрессия)\n",
    "Lasso_MinMaxScal_LassCV = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"regression\", LassoCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью LassoCV\n",
    "Lasso_MinMaxScal_LassCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Lasso_MinMaxScal_LassCV_r2 = r2_score(y_test, Lasso_MinMaxScal_LassCV.predict(X_test))\n",
    "\n",
    "# выводим коэффициенты регуляризации и R2\n",
    "print(\"Опытным путем определено, что LassoCV на масштабированных данных с помощью StandardScaler подобран коэффициент регуляризации 0.00001\")\n",
    "print(\"Опытным путем определено, что LassoCV на масштабированных данных с помощью MinMaxScaler подобран коэффициент регуляризации   0.00001\")\n",
    "print()\n",
    "print(f\"R2 Lasso regression with StandardScaler & LassoCV: {Lasso_StScal_LassCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with MinMaxScaler   & LassoCV: {Lasso_MinMaxScal_LassCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th colspan=\"2\" halign=\"left\">No_scaler</th>\n",
       "      <th colspan=\"2\" halign=\"left\">StandardScaler</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MinMaxScaler</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Params</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>R2</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>R2</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression</th>\n",
       "      <th>Select_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <th>No_alpha</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ridge</th>\n",
       "      <th>Default</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.666222</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.668462</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.676410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearchCV_best</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.668462</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.670031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV_best</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.668751</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.665968</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.670031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Lasso</th>\n",
       "      <th>Default</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.667145</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.623943</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.257392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearchCV_best</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668760</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV_best</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668760</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.668761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Scaler                       No_scaler           StandardScaler            \\\n",
       "Params                           Alpha        R2          Alpha        R2   \n",
       "Regression Select_alpha                                                     \n",
       "Linear     No_alpha                NaN  0.668759            NaN  0.668759   \n",
       "Ridge      Default             1.00000  0.666222        1.00000  0.668462   \n",
       "           GridSearchCV_best   0.00001  0.668759        1.00000  0.668462   \n",
       "           RidgeCV_best        0.01000  0.668751       10.00000  0.665968   \n",
       "Lasso      Default             1.00000  0.667145        1.00000  0.623943   \n",
       "           GridSearchCV_best   0.00001  0.668760        0.00001  0.668759   \n",
       "           LassoCV_best        0.00001  0.668760        0.00001  0.668759   \n",
       "\n",
       "Scaler                       MinMaxScaler            \n",
       "Params                              Alpha        R2  \n",
       "Regression Select_alpha                              \n",
       "Linear     No_alpha                   NaN  0.668759  \n",
       "Ridge      Default                1.00000  0.676410  \n",
       "           GridSearchCV_best      0.10000  0.670031  \n",
       "           RidgeCV_best           0.10000  0.670031  \n",
       "Lasso      Default                1.00000  0.257392  \n",
       "           GridSearchCV_best      0.00001  0.668761  \n",
       "           LassoCV_best           0.00001  0.668761  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сведем результаты расчета r2 в таблицу\n",
    "r2_result = pd.DataFrame(data = [[np.NaN, Linear_r2, np.NaN, Linear_StScal_r2, np.NaN, Linear_MinMaxScal_r2],\n",
    "                                 [1, Ridge_r2, 1, Ridge_StScal_r2, 1, Ridge_MinMaxScal_r2],\n",
    "                                 [Ridge_GSCV.best_params_.get('alpha'), Ridge_GSCV_r2, Ridge_StScal_GSCV.best_params_.get('regression__alpha'), Ridge_StScal_GSCV_r2, Ridge_MinMaxScal_GSCV.best_params_.get('regression__alpha'), Ridge_MinMaxScal_GSCV_r2],\n",
    "                                 [RidCV.alpha_, Ridge_RidCV_r2, 10, Ridge_StScal_RidCV_r2, 0.1, Ridge_MinMaxScal_RidCV_r2],\n",
    "                                 [1, Lasso_r2, 1, Lasso_StScal_r2, 1, Lasso_MinMaxScal_r2],\n",
    "                                 [Lasso_GSCV.best_params_.get('alpha'), Lasso_GSCV_r2, Lasso_StScal_GSCV.best_params_.get('regression__alpha'), Lasso_StScal_GSCV_r2, Lasso_MinMaxScal_GSCV.best_params_.get('regression__alpha'), Lasso_MinMaxScal_GSCV_r2],\n",
    "                                 [LassCV.alpha_, Lasso_LassCV_r2, 0.00001, Lasso_StScal_LassCV_r2, 0.00001, Lasso_MinMaxScal_LassCV_r2]],\n",
    "                         index=pd.MultiIndex.from_tuples([('Linear', 'No_alpha'),\n",
    "                                                          ('Ridge', 'Default'), ('Ridge', 'GridSearchCV_best'), ('Ridge', 'RidgeCV_best'),\n",
    "                                                          ('Lasso', 'Default'), ('Lasso', 'GridSearchCV_best'), ('Lasso', 'LassoCV_best')],\n",
    "                                                         names=['Regression', 'Select_alpha']),\n",
    "                         columns = pd.MultiIndex.from_tuples([('No_scaler', 'Alpha'), ('No_scaler', 'R2'),\n",
    "                                                              ('StandardScaler', 'Alpha'), ('StandardScaler', 'R2'),\n",
    "                                                              ('MinMaxScaler', 'Alpha'), ('MinMaxScaler', 'R2')],\n",
    "                                                             names=['Scaler', 'Params']))\n",
    "r2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- для Ridge регрессии на масштабированных данных подбор коэффициентов регуляризации назначительно ухудшил качество модели;\n",
    "- для Lasso регрессии на масштабированных данных подбор коэффициентов регуляризации значительно улучшил качество модели (стало сопоставимо с подбором коэффициентов без масштабирования);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление попарных произведений масштабированных признаков и их квадратов с коэффициентом регуляризации по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression with StandardScaler & PolynomialFeatures(degree=2): 0.806307\n",
      "R2 Linear regression with MinMaxScaler   & PolynomialFeatures(degree=2): 0.803658\n",
      "R2 Ridge regression with StandardScaler  & PolynomialFeatures(degree=2): 0.816295\n",
      "R2 Ridge regression with MinMaxScaler    & PolynomialFeatures(degree=2): 0.829934\n",
      "R2 Lasso regression with StandardScaler  & PolynomialFeatures(degree=2): 0.732276\n",
      "R2 Lasso regression with MinMaxScaler    & PolynomialFeatures(degree=2): 0.261126\n"
     ]
    }
   ],
   "source": [
    "# создаем pipline (StandardScaler, PolynomialFeatures и линейная регрессия)\n",
    "Linear_StScal_Polynom = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", LinearRegression())])\n",
    "Linear_StScal_Polynom.fit(X_train, y_train)\n",
    "Linear_StScal_Polynom.predict(X_test)\n",
    "Linear_StScal_Polynom_r2 = r2_score(y_test, Linear_StScal_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (MinMaxScaler, PolynomialFeatures и линейная регрессия)\n",
    "Linear_MinMaxScal_Polynom = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", LinearRegression())])\n",
    "Linear_MinMaxScal_Polynom.fit(X_train, y_train)\n",
    "Linear_MinMaxScal_Polynom.predict(X_test)\n",
    "Linear_MinMaxScal_Polynom_r2 = r2_score(y_test, Linear_MinMaxScal_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и Ridge регрессия)\n",
    "Ridge_StScal_Polynom = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Ridge())])\n",
    "Ridge_StScal_Polynom.fit(X_train, y_train)\n",
    "Ridge_StScal_Polynom.predict(X_test)\n",
    "Ridge_StScal_Polynom_r2 = r2_score(y_test, Ridge_StScal_Polynom.predict(X_test))\n",
    "# создаем pipline (MinMaxScaler, PolynomialFeatures и Ridge регрессия)\n",
    "Ridge_MinMaxScal_Polynom = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Ridge())])\n",
    "Ridge_MinMaxScal_Polynom.fit(X_train, y_train)\n",
    "Ridge_MinMaxScal_Polynom.predict(X_test)\n",
    "Ridge_MinMaxScal_Polynom_r2 = r2_score(y_test, Ridge_MinMaxScal_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и Lasso регрессия)\n",
    "Lasso_StScal_Polynom = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Lasso())])\n",
    "Lasso_StScal_Polynom.fit(X_train, y_train)\n",
    "Lasso_StScal_Polynom.predict(X_test)\n",
    "Lasso_StScal_Polynom_r2 = r2_score(y_test, Lasso_StScal_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (MinMaxScaler, PolynomialFeatures и Lasso регрессия)\n",
    "Lasso_MinMaxScal_Polynom = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Lasso())])\n",
    "Lasso_MinMaxScal_Polynom.fit(X_train, y_train)\n",
    "Lasso_MinMaxScal_Polynom.predict(X_test)\n",
    "Lasso_MinMaxScal_Polynom_r2 = r2_score(y_test, Lasso_MinMaxScal_Polynom.predict(X_test))\n",
    "\n",
    "# вывод R2\n",
    "print(f\"R2 Linear regression with StandardScaler & PolynomialFeatures(degree=2): {Linear_StScal_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Linear regression with MinMaxScaler   & PolynomialFeatures(degree=2): {Linear_MinMaxScal_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with StandardScaler  & PolynomialFeatures(degree=2): {Ridge_StScal_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with MinMaxScaler    & PolynomialFeatures(degree=2): {Ridge_MinMaxScal_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with StandardScaler  & PolynomialFeatures(degree=2): {Lasso_StScal_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with MinMaxScaler    & PolynomialFeatures(degree=2): {Lasso_MinMaxScal_Polynom_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расширим задание - посчитаем R2 на масштабированных и немасштабированных признаках с подбором коэффициента регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Linear regression with PolynomialFeatures(degree=2):                                0.806589\n",
      "R2 Ridge regression with PolynomialFeatures(degree=2):                                 0.807154\n",
      "R2 Ridge regression with PolynomialFeatures(degree=2) & GridSearchCV:                  0.811453\n",
      "R2 Ridge regression with StandardScaler & PolynomialFeatures(degree=2) & GridSearchCV: 0.818047\n",
      "R2 Ridge regression with MinMaxScaler & PolynomialFeatures(degree=2) & GridSearchCV:   0.850063\n",
      "R2 Ridge regression with PolynomialFeatures(degree=2) & RidgeCV:                       0.811453\n",
      "R2 Ridge regression with StandardScaler & PolynomialFeatures(degree=2) & RidgeCV:      0.818047\n",
      "R2 Ridge regression with MinMaxScaler & PolynomialFeatures(degree=2) & RidgeCV:        0.850063\n",
      "R2 Lasso regression with PolynomialFeatures(degree=2):                                 0.817783\n",
      "R2 Lasso regression with PolynomialFeatures(degree=2) & GridSearchCV:                  0.792634\n",
      "R2 Lasso regression with StandardScaler & PolynomialFeatures(degree=2) & GridSearchCV: 0.812217\n",
      "R2 Lasso regression with MinMaxScaler & PolynomialFeatures(degree=2) & GridSearchCV:   0.839058\n",
      "R2 Lasso regression with PolynomialFeatures(degree=2) & LassoCV:                       0.792634\n",
      "R2 Lasso regression with StandardScaler & PolynomialFeatures(degree=2) & LassoCV:      0.812217\n",
      "R2 Lasso regression with MinMaxScaler & PolynomialFeatures(degree=2) & LassoCV:        0.839058\n"
     ]
    }
   ],
   "source": [
    "parameters = {'regression__alpha':np.logspace(-5, 5, 11)}\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и линейная регрессия)\n",
    "Linear_Polynom = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", LinearRegression())])\n",
    "Linear_Polynom.fit(X_train, y_train)\n",
    "Linear_Polynom.predict(X_test)\n",
    "Linear_Polynom_r2 = r2_score(y_test, Linear_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и Ridge регрессия)\n",
    "Ridge_Polynom = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Ridge())])\n",
    "Ridge_Polynom.fit(X_train, y_train)\n",
    "Ridge_Polynom.predict(X_test)\n",
    "Ridge_Polynom_r2 = r2_score(y_test, Ridge_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и Ridge регрессия) с подбором коэффициента с помощью GridSearchCV\n",
    "Ridge_Polynom = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Ridge())])\n",
    "Ridge_Polynom_GSCV = GridSearchCV(Ridge_Polynom, parameters)\n",
    "Ridge_Polynom_GSCV.fit(X_train, y_train)\n",
    "Ridge_Polynom_GSCV_r2 = r2_score(y_test, Ridge_Polynom_GSCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и Ridge регрессия) с подбором коэффициента с помощью GridSearchCV\n",
    "Ridge_StScal_Polynom = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Ridge())])\n",
    "Ridge_StScal_Polynom_GSCV = GridSearchCV(Ridge_StScal_Polynom, parameters)\n",
    "Ridge_StScal_Polynom_GSCV.fit(X_train, y_train)\n",
    "Ridge_StScal_Polynom_GSCV_r2 = r2_score(y_test, Ridge_StScal_Polynom_GSCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (MinMaxScaler, PolynomialFeatures и Ridge регрессия) с подбором коэффициента с помощью GridSearchCV\n",
    "Ridge_MinMaxScal_Polynom = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Ridge())])\n",
    "Ridge_MinMaxScal_Polynom_GSCV = GridSearchCV(Ridge_MinMaxScal_Polynom, parameters)\n",
    "Ridge_MinMaxScal_Polynom_GSCV.fit(X_train, y_train)\n",
    "Ridge_MinMaxScal_Polynom_GSCV_r2 = r2_score(y_test, Ridge_MinMaxScal_Polynom_GSCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и RidgeCV для подбора коэффициента)\n",
    "Ridge_Polynom_RidCV = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", RidgeCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью RidgeCV\n",
    "Ridge_Polynom_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Ridge_Polynom_RidCV_r2 = r2_score(y_test, Ridge_Polynom_RidCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и RidgeCV для подбора коэффициента)\n",
    "Ridge_StScal_Polynom_RidCV = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", RidgeCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью RidgeCV\n",
    "Ridge_StScal_Polynom_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Ridge_StScal_Polynom_RidCV_r2 = r2_score(y_test, Ridge_StScal_Polynom_RidCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и RidgeCV для подбора коэффициента)\n",
    "Ridge_MinMaxScal_Polynom_RidCV = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", RidgeCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью RidgeCV\n",
    "Ridge_MinMaxScal_Polynom_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Ridge_MinMaxScal_Polynom_RidCV_r2 = r2_score(y_test, Ridge_MinMaxScal_Polynom_RidCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и Lasso регрессия)\n",
    "Lasso_Polynom = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Lasso())])\n",
    "Lasso_Polynom.fit(X_train, y_train)\n",
    "Lasso_Polynom.predict(X_test)\n",
    "Lasso_Polynom_r2 = r2_score(y_test, Lasso_Polynom.predict(X_test))\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и Lasso регрессия) с подбором коэффициента с помощью GridSearchCV\n",
    "Lasso_Polynom = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Lasso())])\n",
    "Lasso_Polynom_GSCV = GridSearchCV(Lasso_Polynom, parameters)\n",
    "Lasso_Polynom_GSCV.fit(X_train, y_train)\n",
    "Lasso_Polynom_GSCV_r2 = r2_score(y_test, Lasso_Polynom_GSCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и Lasso регрессия) с подбором коэффициента с помощью GridSearchCV\n",
    "Lasso_StScal_Polynom = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Lasso())])\n",
    "Lasso_StScal_Polynom_GSCV = GridSearchCV(Lasso_StScal_Polynom, parameters)\n",
    "Lasso_StScal_Polynom_GSCV.fit(X_train, y_train)\n",
    "Lasso_StScal_Polynom_GSCV_r2 = r2_score(y_test, Lasso_StScal_Polynom_GSCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (MinMaxScaler, PolynomialFeatures и Lasso регрессия) с подбором коэффициента с помощью GridSearchCV\n",
    "Lasso_MinMaxScal_Polynom = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", Lasso())])\n",
    "Lasso_MinMaxScal_Polynom_GSCV = GridSearchCV(Lasso_MinMaxScal_Polynom, parameters)\n",
    "Lasso_MinMaxScal_Polynom_GSCV.fit(X_train, y_train)\n",
    "Lasso_MinMaxScal_Polynom_GSCV_r2 = r2_score(y_test, Lasso_MinMaxScal_Polynom_GSCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (PolynomialFeatures и LassoCV для подбора коэффициента)\n",
    "Lasso_Polynom_RidCV = Pipeline(steps = [(\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", LassoCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью LassoCV\n",
    "Lasso_Polynom_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Lasso_Polynom_RidCV_r2 = r2_score(y_test, Lasso_Polynom_RidCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и LassoCV для подбора коэффициента)\n",
    "Lasso_StScal_Polynom_RidCV = Pipeline(steps = [(\"scaler\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", LassoCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью LassoCV\n",
    "Lasso_StScal_Polynom_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Lasso_StScal_Polynom_RidCV_r2 = r2_score(y_test, Lasso_StScal_Polynom_RidCV.predict(X_test))\n",
    "\n",
    "# создаем pipline (StandardScaler, PolynomialFeatures и LassoCV для подбора коэффициента)\n",
    "Lasso_MinMaxScal_Polynom_RidCV = Pipeline(steps = [(\"scaler\", MinMaxScaler()), (\"polynomial\", PolynomialFeatures(degree=2)), (\"regression\", LassoCV(alphas=np.logspace(-5, 5, 11)))])\n",
    "# подбираем коэффициент регуляризации для pipline с помощью LassoCV\n",
    "Lasso_MinMaxScal_Polynom_RidCV.fit(X_train, y_train)\n",
    "# рассчет R2 на тестовых данных\n",
    "Lasso_MinMaxScal_Polynom_RidCV_r2 = r2_score(y_test, Lasso_MinMaxScal_Polynom_RidCV.predict(X_test))\n",
    "\n",
    "# вывод R2\n",
    "print(f\"R2 Linear regression with PolynomialFeatures(degree=2):                                {Linear_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with PolynomialFeatures(degree=2):                                 {Ridge_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with PolynomialFeatures(degree=2) & GridSearchCV:                  {Ridge_Polynom_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with StandardScaler & PolynomialFeatures(degree=2) & GridSearchCV: {Ridge_StScal_Polynom_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with MinMaxScaler & PolynomialFeatures(degree=2) & GridSearchCV:   {Ridge_MinMaxScal_Polynom_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with PolynomialFeatures(degree=2) & RidgeCV:                       {Ridge_Polynom_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with StandardScaler & PolynomialFeatures(degree=2) & RidgeCV:      {Ridge_StScal_Polynom_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Ridge regression with MinMaxScaler & PolynomialFeatures(degree=2) & RidgeCV:        {Ridge_MinMaxScal_Polynom_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with PolynomialFeatures(degree=2):                                 {Lasso_Polynom_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with PolynomialFeatures(degree=2) & GridSearchCV:                  {Lasso_Polynom_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with StandardScaler & PolynomialFeatures(degree=2) & GridSearchCV: {Lasso_StScal_Polynom_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with MinMaxScaler & PolynomialFeatures(degree=2) & GridSearchCV:   {Lasso_MinMaxScal_Polynom_GSCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with PolynomialFeatures(degree=2) & LassoCV:                       {Lasso_Polynom_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with StandardScaler & PolynomialFeatures(degree=2) & LassoCV:      {Lasso_StScal_Polynom_RidCV_r2:.6f}\")\n",
    "print(f\"R2 Lasso regression with MinMaxScaler & PolynomialFeatures(degree=2) & LassoCV:        {Lasso_MinMaxScal_Polynom_RidCV_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th colspan=\"2\" halign=\"left\">No_scaler</th>\n",
       "      <th colspan=\"2\" halign=\"left\">StandardScaler</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MinMaxScaler</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Polynom</th>\n",
       "      <th>No_polynom</th>\n",
       "      <th>Degree_2</th>\n",
       "      <th>No_polynom</th>\n",
       "      <th>Degree_2</th>\n",
       "      <th>No_polynom</th>\n",
       "      <th>Degree_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression</th>\n",
       "      <th>Select_alpha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <th>No_alpha</th>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.806589</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.806307</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.803658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ridge</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.666222</td>\n",
       "      <td>0.807154</td>\n",
       "      <td>0.668462</td>\n",
       "      <td>0.816295</td>\n",
       "      <td>0.676410</td>\n",
       "      <td>0.829934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearchCV_best</th>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.811453</td>\n",
       "      <td>0.668462</td>\n",
       "      <td>0.818047</td>\n",
       "      <td>0.670031</td>\n",
       "      <td>0.850063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV_best</th>\n",
       "      <td>0.668751</td>\n",
       "      <td>0.811453</td>\n",
       "      <td>0.665968</td>\n",
       "      <td>0.818047</td>\n",
       "      <td>0.670031</td>\n",
       "      <td>0.850063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Lasso</th>\n",
       "      <th>Default</th>\n",
       "      <td>0.667145</td>\n",
       "      <td>0.817783</td>\n",
       "      <td>0.623943</td>\n",
       "      <td>0.732276</td>\n",
       "      <td>0.257392</td>\n",
       "      <td>0.261126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearchCV_best</th>\n",
       "      <td>0.668760</td>\n",
       "      <td>0.792634</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.668761</td>\n",
       "      <td>0.839058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV_best</th>\n",
       "      <td>0.668760</td>\n",
       "      <td>0.792634</td>\n",
       "      <td>0.668759</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.668761</td>\n",
       "      <td>0.839058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Scaler                        No_scaler           StandardScaler            \\\n",
       "Polynom                      No_polynom  Degree_2     No_polynom  Degree_2   \n",
       "Regression Select_alpha                                                      \n",
       "Linear     No_alpha            0.668759  0.806589       0.668759  0.806307   \n",
       "Ridge      Default             0.666222  0.807154       0.668462  0.816295   \n",
       "           GridSearchCV_best   0.668759  0.811453       0.668462  0.818047   \n",
       "           RidgeCV_best        0.668751  0.811453       0.665968  0.818047   \n",
       "Lasso      Default             0.667145  0.817783       0.623943  0.732276   \n",
       "           GridSearchCV_best   0.668760  0.792634       0.668759  0.812217   \n",
       "           LassoCV_best        0.668760  0.792634       0.668759  0.812217   \n",
       "\n",
       "Scaler                       MinMaxScaler            \n",
       "Polynom                        No_polynom  Degree_2  \n",
       "Regression Select_alpha                              \n",
       "Linear     No_alpha              0.668759  0.803658  \n",
       "Ridge      Default               0.676410  0.829934  \n",
       "           GridSearchCV_best     0.670031  0.850063  \n",
       "           RidgeCV_best          0.670031  0.850063  \n",
       "Lasso      Default               0.257392  0.261126  \n",
       "           GridSearchCV_best     0.668761  0.839058  \n",
       "           LassoCV_best          0.668761  0.839058  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сведем результаты расчета r2 в таблицу\n",
    "r2_result = pd.DataFrame(data = [[Linear_r2, Linear_Polynom_r2, Linear_StScal_r2, Linear_StScal_Polynom_r2, Linear_MinMaxScal_r2, Linear_MinMaxScal_Polynom_r2],\n",
    "                                 [Ridge_r2, Ridge_Polynom_r2, Ridge_StScal_r2, Ridge_StScal_Polynom_r2, Ridge_MinMaxScal_r2, Ridge_MinMaxScal_Polynom_r2],\n",
    "                                 [Ridge_GSCV_r2, Ridge_Polynom_GSCV_r2, Ridge_StScal_GSCV_r2, Ridge_StScal_Polynom_GSCV_r2, Ridge_MinMaxScal_GSCV_r2, Ridge_MinMaxScal_Polynom_GSCV_r2],\n",
    "                                 [Ridge_RidCV_r2, Ridge_Polynom_RidCV_r2, Ridge_StScal_RidCV_r2, Ridge_StScal_Polynom_RidCV_r2, Ridge_MinMaxScal_RidCV_r2, Ridge_MinMaxScal_Polynom_RidCV_r2],\n",
    "                                 [Lasso_r2, Lasso_Polynom_r2, Lasso_StScal_r2, Lasso_StScal_Polynom_r2, Lasso_MinMaxScal_r2, Lasso_MinMaxScal_Polynom_r2],\n",
    "                                 [Lasso_GSCV_r2, Lasso_Polynom_GSCV_r2, Lasso_StScal_GSCV_r2, Lasso_StScal_Polynom_GSCV_r2, Lasso_MinMaxScal_GSCV_r2, Lasso_MinMaxScal_Polynom_GSCV_r2],\n",
    "                                 [Lasso_LassCV_r2, Lasso_Polynom_RidCV_r2, Lasso_StScal_LassCV_r2, Lasso_StScal_Polynom_RidCV_r2, Lasso_MinMaxScal_LassCV_r2, Lasso_MinMaxScal_Polynom_RidCV_r2]],\n",
    "                         index=pd.MultiIndex.from_tuples([('Linear', 'No_alpha'),\n",
    "                                                            ('Ridge', 'Default'), ('Ridge', 'GridSearchCV_best'), ('Ridge', 'RidgeCV_best'),\n",
    "                                                            ('Lasso', 'Default'), ('Lasso', 'GridSearchCV_best'), ('Lasso', 'LassoCV_best')],\n",
    "                                                          names=['Regression', 'Select_alpha']),\n",
    "                         columns = pd.MultiIndex.from_tuples([('No_scaler', 'No_polynom'), ('No_scaler', 'Degree_2'),\n",
    "                                                              ('StandardScaler', 'No_polynom'), ('StandardScaler', 'Degree_2'),\n",
    "                                                              ('MinMaxScaler', 'No_polynom'), ('MinMaxScaler', 'Degree_2')],\n",
    "                                                             names=['Scaler', 'Polynom']))\n",
    "r2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- при добавлении попарных произведений признаков и их квадратов очень существенно улучшилось качество моделей;\n",
    "- для рассматриваемых данных самое высокое значение метрики r2 для Ridge регрессии на масштабированных признаках с помощью MinMaxScaler и добавлением попарных произведений признаков и их квадратов с подбором коэффициента регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, MinMaxScaler()),\n",
       "                (&#x27;polynomial&#x27;, PolynomialFeatures(degree=5)),\n",
       "                (&#x27;regression&#x27;, Ridge())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, MinMaxScaler()),\n",
       "                (&#x27;polynomial&#x27;, PolynomialFeatures(degree=5)),\n",
       "                (&#x27;regression&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(degree=5)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', MinMaxScaler()),\n",
       "                ('polynomial', PolynomialFeatures(degree=5)),\n",
       "                ('regression', Ridge())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('imputer', StandardScaler()),\n",
    "                     ('polynomial', PolynomialFeatures()),\n",
    "                     ('regression', Lasso())])\n",
    "parameters = {'imputer':[StandardScaler(), MinMaxScaler()],\n",
    "              'polynomial__degree':np.arange(1,6,1),\n",
    "              'regression':[Lasso(), Ridge()],\n",
    "              'regression__alpha':np.logspace(-5, 5, 11)}\n",
    "select_model = GridSearchCV(pipeline, parameters, scoring='r2')\n",
    "select_model.fit(X_train, y_train)\n",
    "select_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer': MinMaxScaler(),\n",
       " 'polynomial__degree': 5,\n",
       " 'regression': Ridge(),\n",
       " 'regression__alpha': 1.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Лучшие подобранные параметры\n",
    "select_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Best model (MinMaxScaler, PolynomialFeatures(degree=5), Ridge(alpha=1)): 0.859305\n"
     ]
    }
   ],
   "source": [
    "Best_model_r2 = r2_score(y_test, select_model.predict(X_test))\n",
    "print(f\"R2 Best model (MinMaxScaler, PolynomialFeatures(degree=5), Ridge(alpha=1)): {Best_model_r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- для рассматриваемых данных наилучшими параметрами (из предложенных) оказались метод масштабирования MinMaxScaler, 5-я степень полинома, Ridge регрессия с коэффициентом регуляризации 1;\n",
    "- качество модели улучшилось по сравнению с предыдущими вариантами;\n",
    "- существенно снизились трудозатраты на поиск оптимальных параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13  \n",
       "0  United-States  \n",
       "1  United-States  \n",
       "2  United-States  \n",
       "3  United-States  \n",
       "4           Cuba  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим копию датафрейма без целевой переменной (признаки)\n",
    "X = data.loc[:,0:13].copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: 14, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим копию столбца 14 датафрейма (целевая переменная)\n",
    "y = data[14].copy()\n",
    "# заменим значения менее 50к на 0, значения более 50к на 1\n",
    "y[y == '<=50K'] = 0\n",
    "y[y == '>50K'] = 1\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37155\n",
       "1    11687\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# преобразуем тип данных целевой переменной в int\n",
    "y = y.astype(int)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### результаты расчета метрик f1 будет отличаться исходя из того, что в целевой переменной будет True, а что False (<=50K или >50K), так как при разном выборе самым частым классом будет 0 или 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В последующих заданиях будем оперировать 2 вариантами целевой переменной:\n",
    "- самое частое значение 0 (<=50K -> 0; >50K -> 1) - соответствует исходному y;\n",
    "- самое частое значение 1 (<=50K -> 1; >50K -> 0) - соответствует инвертированному y (abs(y-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете отсутствуют пропущенные значения (знак \"?\" пока не трогаем)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1       2          3   4                   5               6   \\\n",
       "48837  39  Private  215419  Bachelors  13            Divorced  Prof-specialty   \n",
       "48838  64        ?  321403    HS-grad   9             Widowed               ?   \n",
       "48839  38  Private  374983  Bachelors  13  Married-civ-spouse  Prof-specialty   \n",
       "\n",
       "                   7      8       9  10 11  12             13  \n",
       "48837   Not-in-family  White  Female  0  0  36  United-States  \n",
       "48838  Other-relative  Black    Male  0  0  40  United-States  \n",
       "48839         Husband  White    Male  0  0  50  United-States  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# если бы были пропущенные значения (NaN)\n",
    "imp = SimpleImputer(missing_values=np.NaN, strategy=\"most_frequent\")\n",
    "X_imp = pd.DataFrame(imp.fit_transform(X))\n",
    "X_imp.loc[48837:48839]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      int64\n",
       "1     object\n",
       "2      int64\n",
       "3     object\n",
       "4      int64\n",
       "5     object\n",
       "6     object\n",
       "7     object\n",
       "8     object\n",
       "9     object\n",
       "10     int64\n",
       "11     int64\n",
       "12     int64\n",
       "13    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# типы колонок\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0       2   4     10  11  12\n",
       "0  39   77516  13  2174   0  40\n",
       "1  50   83311  13     0   0  13\n",
       "2  38  215646   9     0   0  40"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# колонки с числовыми переменными\n",
    "numerical = list(X.select_dtypes('number').columns)\n",
    "X[numerical].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1          3                   5                  6   \\\n",
       "0         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "\n",
       "              7      8     9              13  \n",
       "0  Not-in-family  White  Male  United-States  \n",
       "1        Husband  White  Male  United-States  \n",
       "2  Not-in-family  White  Male  United-States  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# колонки с категориальными переменными\n",
    "categorical = list(X.select_dtypes('object').columns)\n",
    "X[categorical].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формирование пайплайна по предобработке данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_?</th>\n",
       "      <th>x1_Federal-gov</th>\n",
       "      <th>x1_Local-gov</th>\n",
       "      <th>x1_Never-worked</th>\n",
       "      <th>x1_Private</th>\n",
       "      <th>x1_Self-emp-inc</th>\n",
       "      <th>x1_Self-emp-not-inc</th>\n",
       "      <th>x1_State-gov</th>\n",
       "      <th>x1_Without-pay</th>\n",
       "      <th>x3_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>x13_Trinadad&amp;Tobago</th>\n",
       "      <th>x13_United-States</th>\n",
       "      <th>x13_Vietnam</th>\n",
       "      <th>x13_Yugoslavia</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.209130</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.245379</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.054551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1_?  x1_Federal-gov  x1_Local-gov  x1_Never-worked  x1_Private  \\\n",
       "0       0.0             0.0           0.0              0.0         0.0   \n",
       "1       0.0             0.0           0.0              0.0         0.0   \n",
       "2       0.0             0.0           0.0              0.0         1.0   \n",
       "3       0.0             0.0           0.0              0.0         1.0   \n",
       "4       0.0             0.0           0.0              0.0         1.0   \n",
       "...     ...             ...           ...              ...         ...   \n",
       "48837   0.0             0.0           0.0              0.0         1.0   \n",
       "48838   1.0             0.0           0.0              0.0         0.0   \n",
       "48839   0.0             0.0           0.0              0.0         1.0   \n",
       "48840   0.0             0.0           0.0              0.0         1.0   \n",
       "48841   0.0             0.0           0.0              0.0         0.0   \n",
       "\n",
       "       x1_Self-emp-inc  x1_Self-emp-not-inc  x1_State-gov  x1_Without-pay  \\\n",
       "0                  0.0                  0.0           1.0             0.0   \n",
       "1                  0.0                  1.0           0.0             0.0   \n",
       "2                  0.0                  0.0           0.0             0.0   \n",
       "3                  0.0                  0.0           0.0             0.0   \n",
       "4                  0.0                  0.0           0.0             0.0   \n",
       "...                ...                  ...           ...             ...   \n",
       "48837              0.0                  0.0           0.0             0.0   \n",
       "48838              0.0                  0.0           0.0             0.0   \n",
       "48839              0.0                  0.0           0.0             0.0   \n",
       "48840              0.0                  0.0           0.0             0.0   \n",
       "48841              1.0                  0.0           0.0             0.0   \n",
       "\n",
       "       x3_10th  ...  x13_Trinadad&Tobago  x13_United-States  x13_Vietnam  \\\n",
       "0          0.0  ...                  0.0                1.0          0.0   \n",
       "1          0.0  ...                  0.0                1.0          0.0   \n",
       "2          0.0  ...                  0.0                1.0          0.0   \n",
       "3          0.0  ...                  0.0                1.0          0.0   \n",
       "4          0.0  ...                  0.0                0.0          0.0   \n",
       "...        ...  ...                  ...                ...          ...   \n",
       "48837      0.0  ...                  0.0                1.0          0.0   \n",
       "48838      0.0  ...                  0.0                1.0          0.0   \n",
       "48839      0.0  ...                  0.0                1.0          0.0   \n",
       "48840      0.0  ...                  0.0                1.0          0.0   \n",
       "48841      0.0  ...                  0.0                1.0          0.0   \n",
       "\n",
       "       x13_Yugoslavia         0         2         4        10   11        12  \n",
       "0                 0.0  0.301370  0.044131  0.800000  0.021740  0.0  0.397959  \n",
       "1                 0.0  0.452055  0.048052  0.800000  0.000000  0.0  0.122449  \n",
       "2                 0.0  0.287671  0.137581  0.533333  0.000000  0.0  0.397959  \n",
       "3                 0.0  0.493151  0.150486  0.400000  0.000000  0.0  0.397959  \n",
       "4                 0.0  0.150685  0.220635  0.800000  0.000000  0.0  0.397959  \n",
       "...               ...       ...       ...       ...       ...  ...       ...  \n",
       "48837             0.0  0.301370  0.137428  0.800000  0.000000  0.0  0.357143  \n",
       "48838             0.0  0.643836  0.209130  0.533333  0.000000  0.0  0.397959  \n",
       "48839             0.0  0.287671  0.245379  0.800000  0.000000  0.0  0.500000  \n",
       "48840             0.0  0.369863  0.048444  0.800000  0.054551  0.0  0.397959  \n",
       "48841             0.0  0.246575  0.114919  0.800000  0.000000  0.0  0.602041  \n",
       "\n",
       "[48842 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Выведим датасет с предобработанными данными\n",
    "preprocessor_base.fit(X)\n",
    "\n",
    "# числовые названия колонок извлекаются с префиксом 'x' - добавим x перед числами в списке имен категорийных колонок\n",
    "categorical_extract = []\n",
    "for i in categorical:\n",
    "    categorical_extract.append('x' + str(i))\n",
    "\n",
    "# извлечем названия создаваемых колонок с помощью OneHotEncoder\n",
    "categorical_columns = preprocessor_base.named_transformers_['cat']['encoder'].get_feature_names(categorical_extract)\n",
    "columns_base = np.append(categorical_columns, numerical)\n",
    "\n",
    "# выведим полученный датасет (в принципе названия столбцов особо не нужны)\n",
    "display(pd.DataFrame(preprocessor_base.transform(X), columns=columns_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    37155\n",
       "1    11687\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определим самый частый класс целевой переменной (для <=50K -> 0; >50K -> 1)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое частое значение целевой переменной 0 (<=50K -> 0; >50K -> 1) - соответствует исходному y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy DummyClassifier (0 most frequent): 0.7607\n",
      "f1_score DummyClassifier (0 most frequent): 0.0000\n"
     ]
    }
   ],
   "source": [
    "# создадим модель, предсказывающую наиболее частый класс\n",
    "Dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# инвертируем значения целевой переменной (иначе не считается f1_score)\n",
    "Dummy_clf.fit(X, y)\n",
    "\n",
    "# расчет accurancy и f1 score\n",
    "DummyCl_accuracy = accuracy_score(y, Dummy_clf.predict(X))\n",
    "DummyCl_0mf_f1 = f1_score(y, Dummy_clf.predict(X))\n",
    "\n",
    "# выведем значения accurancy и f1 score\n",
    "print(f\"accuracy DummyClassifier (0 most frequent): {DummyCl_accuracy:.4f}\")\n",
    "print(f\"f1_score DummyClassifier (0 most frequent): {DummyCl_0mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое частое значение целевой переменной 1 (<=50K -> 1; >50K -> 0) - соответствует соответствует инвертированному y (abs(y-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy DummyClassifier (1 most frequent): 0.7607\n",
      "f1_score DummyClassifier (1 most frequent): 0.8641\n"
     ]
    }
   ],
   "source": [
    "# создадим модель, предсказывающую наиболее частый класс\n",
    "Dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# инвертируем значения целевой переменной (иначе не считается f1_score)\n",
    "Dummy_clf.fit(X, abs(y-1))\n",
    "\n",
    "# расчет accurancy и f1 score\n",
    "DummyCl_accuracy = accuracy_score(abs(y-1), Dummy_clf.predict(X))\n",
    "DummyCl_1mf_f1 = f1_score(abs(y-1), Dummy_clf.predict(X))\n",
    "\n",
    "# выведем значения accurancy и f1 score\n",
    "print(f\"accuracy DummyClassifier (1 most frequent): {DummyCl_accuracy:.4f}\")\n",
    "print(f\"f1_score DummyClassifier (1 most frequent): {DummyCl_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### посчитаем accurancy и f1 score аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое частое значение целевой переменной 0 (<=50K -> 0; >50K -> 1) - соответствует исходному y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_predict</th>\n",
       "      <th>y_real</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_predict  y_real confusion_matrix\n",
       "48840          0       0               TN\n",
       "48841          0       1               FN"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сформируем датасет с предсказанным значением и истинным\n",
    "df = pd.DataFrame(data = {'y_predict':0, 'y_real':y})\n",
    "# Добавим колонку confusion_matrix\n",
    "df['confusion_matrix'] = np.NaN\n",
    "for i in range(len(df)):\n",
    "    if (df['y_predict'][i] == 1) & (df['y_real'][i] == 1): df.iat[i,2] = 'TP'\n",
    "    if (df['y_predict'][i] == 1) & (df['y_real'][i] == 0): df.iat[i,2] = 'FP'\n",
    "    if (df['y_predict'][i] == 0) & (df['y_real'][i] == 1): df.iat[i,2] = 'FN'\n",
    "    if (df['y_predict'][i] == 0) & (df['y_real'][i] == 0): df.iat[i,2] = 'TN'\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля правильных ответов(аккуратность): $ 𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦(𝑎,𝑋) = \\frac{1}{l} \\sum_{i=1}^l[𝑎(𝑥_𝑖)=𝑦_𝑖  ] $  \n",
    "$ Точность (precision) = \\frac{𝑇𝑃}{(𝑇𝑃+𝐹𝑃)} $  \n",
    "$ Полнота (recall) = \\frac{𝑇𝑃}{(𝑇𝑃+𝐹N)} $  \n",
    "F1-мера $ F1 = \\frac {2∗precision∗recall}{precision+recall} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy most frequent (0 most frequent):  0.7607\n",
      "precision most frequent (0 most frequent): nan\n",
      "recall most frequent (0 most frequent):    0.0000\n",
      "f1 most frequent (0 most frequent):        nan\n"
     ]
    }
   ],
   "source": [
    "# Доля правильных ответов (accurancy) будет равна отношению суммы true positive (TP) и true negative (TP) к количеству предсказанных ответов\n",
    "most_freq_accuracy = df[(df.confusion_matrix == 'TP') | (df.confusion_matrix == 'TN')]['confusion_matrix'].count()/df[df.confusion_matrix.notnull()]['confusion_matrix'].count()\n",
    "print(f\"accuracy most frequent (0 most frequent):  {most_freq_accuracy:.4f}\")\n",
    "\n",
    "# точность и полнота\n",
    "most_freq_0mf_precision = df[(df.confusion_matrix == 'TP')]['confusion_matrix'].count()/df[(df.confusion_matrix == 'TP') | (df.confusion_matrix == 'FP')]['confusion_matrix'].count()\n",
    "most_freq_0mf_recall = df[(df.confusion_matrix == 'TP')]['confusion_matrix'].count()/df[(df.confusion_matrix == 'TP') | (df.confusion_matrix == 'FN')]['confusion_matrix'].count()\n",
    "print(f\"precision most frequent (0 most frequent): {most_freq_0mf_precision:.4f}\")\n",
    "print(f\"recall most frequent (0 most frequent):    {most_freq_0mf_recall:.4f}\")\n",
    "\n",
    "# f1\n",
    "most_freq_0mf_f1 = (2*most_freq_0mf_precision*most_freq_0mf_recall)/(most_freq_0mf_precision+most_freq_0mf_recall)\n",
    "print(f\"f1 most frequent (0 most frequent):        {most_freq_0mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое частое значение целевой переменной 1 (<=50K -> 1; >50K -> 0) - соответствует инвертированному y (abs(y-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_predict</th>\n",
       "      <th>y_real</th>\n",
       "      <th>confusion_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_predict  y_real confusion_matrix\n",
       "48840          1       1               TP\n",
       "48841          1       0               FP"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сформируем датасет с предсказанным значением и истинным\n",
    "df = pd.DataFrame(data = {'y_predict':1, 'y_real':abs(y-1)})\n",
    "# Добавим колонку confusion_matrix\n",
    "df['confusion_matrix'] = np.NaN\n",
    "for i in range(len(df)):\n",
    "    if (df['y_predict'][i] == 1) & (df['y_real'][i] == 1): df.iat[i,2] = 'TP'\n",
    "    if (df['y_predict'][i] == 1) & (df['y_real'][i] == 0): df.iat[i,2] = 'FP'\n",
    "    if (df['y_predict'][i] == 0) & (df['y_real'][i] == 1): df.iat[i,2] = 'FN'\n",
    "    if (df['y_predict'][i] == 0) & (df['y_real'][i] == 0): df.iat[i,2] = 'TN'\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy most frequent (1 most frequent):  0.7607\n",
      "precision most frequent (1 most frequent): 0.7607\n",
      "recall most frequent (1 most frequent):    1.0000\n",
      "f1 most frequent (1 most frequent):        0.8641\n"
     ]
    }
   ],
   "source": [
    "# Доля правильных ответов (accurancy) будет равна отношению суммы true positive (TP) и true negative (TP) к количеству предсказанных ответов\n",
    "most_freq_accuracy = df[(df.confusion_matrix == 'TP') | (df.confusion_matrix == 'TN')]['confusion_matrix'].count()/df[df.confusion_matrix.notnull()]['confusion_matrix'].count()\n",
    "print(f\"accuracy most frequent (1 most frequent):  {most_freq_accuracy:.4f}\")\n",
    "\n",
    "# точность и полнота\n",
    "most_freq_precision = df[(df.confusion_matrix == 'TP')]['confusion_matrix'].count()/df[(df.confusion_matrix == 'TP') | (df.confusion_matrix == 'FP')]['confusion_matrix'].count()\n",
    "most_freq_recall = df[(df.confusion_matrix == 'TP')]['confusion_matrix'].count()/df[(df.confusion_matrix == 'TP') | (df.confusion_matrix == 'FN')]['confusion_matrix'].count()\n",
    "print(f\"precision most frequent (1 most frequent): {most_freq_precision:.4f}\")\n",
    "print(f\"recall most frequent (1 most frequent):    {most_freq_recall:.4f}\")\n",
    "\n",
    "# f1\n",
    "most_freq_1mf_f1 = (2*most_freq_precision*most_freq_recall)/(most_freq_precision+most_freq_recall)\n",
    "print(f\"f1 most frequent (1 most frequent):        {most_freq_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выоды:\n",
    "- расчеты совпали;\n",
    "- при предсказании только самого частого класса в целевой переменной accurancy = 0.7607 независимо от того, 0 самое частое значение или 1;\n",
    "- при предсказании только самого частого класса в целевой переменной f1 зависит от того, 0 или 1 самое частое значение целевой переменной;\n",
    "- при самом частом значении целевой переменной 0 (<=50K -> 0; >50K -> 1) f1 = 0;\n",
    "- при самом частом значении целевой переменной 1 (<=50K -> 1; >50K -> 0) f1 = 0.8641"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score. Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy LogisticRegression cross_val_score:             0.8509\n",
      "f1 LogisticRegression cross_val_score (0 most frequent): 0.6558\n",
      "f1 LogisticRegression cross_val_score (1 most frequent): 0.9048\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_LogReg = Pipeline([('preprocessor', preprocessor_base), ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "LogReg_accuracy = cross_val_score(pipe_LogReg, X, y, cv=5, scoring='accuracy').mean()\n",
    "LogReg_0mf_f1 = cross_val_score(pipe_LogReg, X, y, cv=5, scoring='f1').mean()\n",
    "LogReg_1mf_f1 = cross_val_score(pipe_LogReg, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy LogisticRegression cross_val_score:             {LogReg_accuracy:.4f}\")\n",
    "print(f\"f1 LogisticRegression cross_val_score (0 most frequent): {LogReg_0mf_f1:.4f}\")\n",
    "print(f\"f1 LogisticRegression cross_val_score (1 most frequent): {LogReg_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy SVC cross_val_score:             0.8400\n",
      "f1 SVC cross_val_score (0 most frequent): 0.6201\n",
      "f1 SVC cross_val_score (1 most frequent): 0.8986\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_SVC = Pipeline([('preprocessor', preprocessor_base), ('classifier', SVC(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "SVC_accuracy = cross_val_score(pipe_SVC, X, y, cv=5, scoring='accuracy').mean()\n",
    "SVC_0mf_f1 = cross_val_score(pipe_SVC, X, y, cv=5, scoring='f1').mean()\n",
    "SVC_1mf_f1 = cross_val_score(pipe_SVC, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy SVC cross_val_score:             {SVC_accuracy:.4f}\")\n",
    "print(f\"f1 SVC cross_val_score (0 most frequent): {SVC_0mf_f1:.4f}\")\n",
    "print(f\"f1 SVC cross_val_score (1 most frequent): {SVC_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy LinearSVC cross_val_score:             0.8529\n",
      "f1 LinearSVC cross_val_score (0 most frequent): 0.6578\n",
      "f1 LinearSVC cross_val_score (1 most frequent): 0.9063\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_LinSVC = Pipeline([('preprocessor', preprocessor_base), ('classifier', LinearSVC(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "LinSVC_accuracy = cross_val_score(pipe_LinSVC, X, y, cv=5, scoring='accuracy').mean()\n",
    "LinSVC_0mf_f1 = cross_val_score(pipe_LinSVC, X, y, cv=5, scoring='f1').mean()\n",
    "LinSVC_1mf_f1 = cross_val_score(pipe_LinSVC, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy LinearSVC cross_val_score:             {LinSVC_accuracy:.4f}\")\n",
    "print(f\"f1 LinearSVC cross_val_score (0 most frequent): {LinSVC_0mf_f1:.4f}\")\n",
    "print(f\"f1 LinearSVC cross_val_score (1 most frequent): {LinSVC_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DummyClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LinearSVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760718</td>\n",
       "      <td>0.850907</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>0.852914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0_most_frequent</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655816</td>\n",
       "      <td>0.620083</td>\n",
       "      <td>0.657816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1_most_frequent</th>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>0.906322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DummyClassifier  LogisticRegression       SVC  LinearSVC\n",
       "accuracy                   0.760718            0.850907  0.839974   0.852914\n",
       "f1_0_most_frequent         0.000000            0.655816  0.620083   0.657816\n",
       "f1_1_most_frequent         0.864100            0.904843  0.898648   0.906322"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сведем результаты в таблицу\n",
    "cross_val_score_result = pd.DataFrame(data = [[DummyCl_accuracy, LogReg_accuracy, SVC_accuracy, LinSVC_accuracy],\n",
    "                                              [DummyCl_0mf_f1, LogReg_0mf_f1, SVC_0mf_f1, LinSVC_0mf_f1],\n",
    "                                              [DummyCl_1mf_f1, LogReg_1mf_f1, SVC_1mf_f1, LinSVC_1mf_f1],\n",
    "                                              ],\n",
    "                                      index = ['accuracy', 'f1_0_most_frequent', 'f1_1_most_frequent'],\n",
    "                                      columns = ['DummyClassifier', 'LogisticRegression', 'SVC', 'LinearSVC'])\n",
    "cross_val_score_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score значительно выше, чем по алгоритму DummyClassifier (предсказание наиболее частого класса);\n",
    "- результаты по алгоритмам LogisticRegression и LinearSVC сопоставимы, LinearSVC в отработал быстрее (в моем случае примерно в 2 раза)\n",
    "- результаты по алгоритму SVC (метод опорных векторов) несколько хуже, чем по алгоритмам LogisticRegression и LinearSVC;\n",
    "- SVC отработал в разы дольше, чем LogisticRegression и LinearSVC (в моем случае в 57 и 118 раз соответственно);\n",
    "- во всех случаях метрика f1 лучше, если наиболее частым классом является положительный класс (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "самое частое значение целевой переменной  0 (<=50K -> 0; >50K -> 1) - соответствует исходному y;\n",
    "самое частое значение целевой переменной  1 (<=50K -> 1; >50K -> 0) - соответствует инвертированному y (abs(y-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пайплайн по предобработке данных без обработки пропусков\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "\n",
    "# Выведим датасет с предобработанными данными\n",
    "preprocessor_base.fit(X)\n",
    "\n",
    "# числовые названия колонок извлекаются с префиксом 'x' - добавим x перед числами в списке имен категорийных колонок\n",
    "categorical_extract = []\n",
    "for i in categorical:\n",
    "    categorical_extract.append('x' + str(i))\n",
    "\n",
    "# извлечем названия создаваемых колонок с помощью OneHotEncoder\n",
    "categorical_columns = preprocessor_base.named_transformers_['cat']['encoder'].get_feature_names(categorical_extract)\n",
    "columns_base = np.append(categorical_columns, numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формирование пайплайна по предобработке данных с заменой пропусков (?) на самые частые значения\n",
    "# ? может присутствовать только в нечисловых столбцах -  добавим в preprocessor для категорийных данных SimpleImputer\n",
    "preprocessor_imputer = ColumnTransformer([('cat', Pipeline([('imputer', SimpleImputer(missing_values='?', strategy=\"most_frequent\")), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                          ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет без обработки пропусков:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_?</th>\n",
       "      <th>x1_Federal-gov</th>\n",
       "      <th>x1_Local-gov</th>\n",
       "      <th>x1_Never-worked</th>\n",
       "      <th>x1_Private</th>\n",
       "      <th>x1_Self-emp-inc</th>\n",
       "      <th>x1_Self-emp-not-inc</th>\n",
       "      <th>x1_State-gov</th>\n",
       "      <th>x1_Without-pay</th>\n",
       "      <th>x3_10th</th>\n",
       "      <th>...</th>\n",
       "      <th>x13_Trinadad&amp;Tobago</th>\n",
       "      <th>x13_United-States</th>\n",
       "      <th>x13_Vietnam</th>\n",
       "      <th>x13_Yugoslavia</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.209130</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.245379</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.054551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1_?  x1_Federal-gov  x1_Local-gov  x1_Never-worked  x1_Private  \\\n",
       "0       0.0             0.0           0.0              0.0         0.0   \n",
       "1       0.0             0.0           0.0              0.0         0.0   \n",
       "2       0.0             0.0           0.0              0.0         1.0   \n",
       "3       0.0             0.0           0.0              0.0         1.0   \n",
       "4       0.0             0.0           0.0              0.0         1.0   \n",
       "...     ...             ...           ...              ...         ...   \n",
       "48837   0.0             0.0           0.0              0.0         1.0   \n",
       "48838   1.0             0.0           0.0              0.0         0.0   \n",
       "48839   0.0             0.0           0.0              0.0         1.0   \n",
       "48840   0.0             0.0           0.0              0.0         1.0   \n",
       "48841   0.0             0.0           0.0              0.0         0.0   \n",
       "\n",
       "       x1_Self-emp-inc  x1_Self-emp-not-inc  x1_State-gov  x1_Without-pay  \\\n",
       "0                  0.0                  0.0           1.0             0.0   \n",
       "1                  0.0                  1.0           0.0             0.0   \n",
       "2                  0.0                  0.0           0.0             0.0   \n",
       "3                  0.0                  0.0           0.0             0.0   \n",
       "4                  0.0                  0.0           0.0             0.0   \n",
       "...                ...                  ...           ...             ...   \n",
       "48837              0.0                  0.0           0.0             0.0   \n",
       "48838              0.0                  0.0           0.0             0.0   \n",
       "48839              0.0                  0.0           0.0             0.0   \n",
       "48840              0.0                  0.0           0.0             0.0   \n",
       "48841              1.0                  0.0           0.0             0.0   \n",
       "\n",
       "       x3_10th  ...  x13_Trinadad&Tobago  x13_United-States  x13_Vietnam  \\\n",
       "0          0.0  ...                  0.0                1.0          0.0   \n",
       "1          0.0  ...                  0.0                1.0          0.0   \n",
       "2          0.0  ...                  0.0                1.0          0.0   \n",
       "3          0.0  ...                  0.0                1.0          0.0   \n",
       "4          0.0  ...                  0.0                0.0          0.0   \n",
       "...        ...  ...                  ...                ...          ...   \n",
       "48837      0.0  ...                  0.0                1.0          0.0   \n",
       "48838      0.0  ...                  0.0                1.0          0.0   \n",
       "48839      0.0  ...                  0.0                1.0          0.0   \n",
       "48840      0.0  ...                  0.0                1.0          0.0   \n",
       "48841      0.0  ...                  0.0                1.0          0.0   \n",
       "\n",
       "       x13_Yugoslavia         0         2         4        10   11        12  \n",
       "0                 0.0  0.301370  0.044131  0.800000  0.021740  0.0  0.397959  \n",
       "1                 0.0  0.452055  0.048052  0.800000  0.000000  0.0  0.122449  \n",
       "2                 0.0  0.287671  0.137581  0.533333  0.000000  0.0  0.397959  \n",
       "3                 0.0  0.493151  0.150486  0.400000  0.000000  0.0  0.397959  \n",
       "4                 0.0  0.150685  0.220635  0.800000  0.000000  0.0  0.397959  \n",
       "...               ...       ...       ...       ...       ...  ...       ...  \n",
       "48837             0.0  0.301370  0.137428  0.800000  0.000000  0.0  0.357143  \n",
       "48838             0.0  0.643836  0.209130  0.533333  0.000000  0.0  0.397959  \n",
       "48839             0.0  0.287671  0.245379  0.800000  0.000000  0.0  0.500000  \n",
       "48840             0.0  0.369863  0.048444  0.800000  0.054551  0.0  0.397959  \n",
       "48841             0.0  0.246575  0.114919  0.800000  0.000000  0.0  0.602041  \n",
       "\n",
       "[48842 rows x 108 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет, в котором пропуски (?) заменены на самые частые значения:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1_Federal-gov</th>\n",
       "      <th>x1_Local-gov</th>\n",
       "      <th>x1_Never-worked</th>\n",
       "      <th>x1_Private</th>\n",
       "      <th>x1_Self-emp-inc</th>\n",
       "      <th>x1_Self-emp-not-inc</th>\n",
       "      <th>x1_State-gov</th>\n",
       "      <th>x1_Without-pay</th>\n",
       "      <th>x3_10th</th>\n",
       "      <th>x3_11th</th>\n",
       "      <th>...</th>\n",
       "      <th>x13_Trinadad&amp;Tobago</th>\n",
       "      <th>x13_United-States</th>\n",
       "      <th>x13_Vietnam</th>\n",
       "      <th>x13_Yugoslavia</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.137428</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.209130</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.245379</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369863</td>\n",
       "      <td>0.048444</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.054551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246575</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1_Federal-gov  x1_Local-gov  x1_Never-worked  x1_Private  \\\n",
       "0                 0.0           0.0              0.0         0.0   \n",
       "1                 0.0           0.0              0.0         0.0   \n",
       "2                 0.0           0.0              0.0         1.0   \n",
       "3                 0.0           0.0              0.0         1.0   \n",
       "4                 0.0           0.0              0.0         1.0   \n",
       "...               ...           ...              ...         ...   \n",
       "48837             0.0           0.0              0.0         1.0   \n",
       "48838             0.0           0.0              0.0         1.0   \n",
       "48839             0.0           0.0              0.0         1.0   \n",
       "48840             0.0           0.0              0.0         1.0   \n",
       "48841             0.0           0.0              0.0         0.0   \n",
       "\n",
       "       x1_Self-emp-inc  x1_Self-emp-not-inc  x1_State-gov  x1_Without-pay  \\\n",
       "0                  0.0                  0.0           1.0             0.0   \n",
       "1                  0.0                  1.0           0.0             0.0   \n",
       "2                  0.0                  0.0           0.0             0.0   \n",
       "3                  0.0                  0.0           0.0             0.0   \n",
       "4                  0.0                  0.0           0.0             0.0   \n",
       "...                ...                  ...           ...             ...   \n",
       "48837              0.0                  0.0           0.0             0.0   \n",
       "48838              0.0                  0.0           0.0             0.0   \n",
       "48839              0.0                  0.0           0.0             0.0   \n",
       "48840              0.0                  0.0           0.0             0.0   \n",
       "48841              1.0                  0.0           0.0             0.0   \n",
       "\n",
       "       x3_10th  x3_11th  ...  x13_Trinadad&Tobago  x13_United-States  \\\n",
       "0          0.0      0.0  ...                  0.0                1.0   \n",
       "1          0.0      0.0  ...                  0.0                1.0   \n",
       "2          0.0      0.0  ...                  0.0                1.0   \n",
       "3          0.0      1.0  ...                  0.0                1.0   \n",
       "4          0.0      0.0  ...                  0.0                0.0   \n",
       "...        ...      ...  ...                  ...                ...   \n",
       "48837      0.0      0.0  ...                  0.0                1.0   \n",
       "48838      0.0      0.0  ...                  0.0                1.0   \n",
       "48839      0.0      0.0  ...                  0.0                1.0   \n",
       "48840      0.0      0.0  ...                  0.0                1.0   \n",
       "48841      0.0      0.0  ...                  0.0                1.0   \n",
       "\n",
       "       x13_Vietnam  x13_Yugoslavia         0         2         4        10  \\\n",
       "0              0.0             0.0  0.301370  0.044131  0.800000  0.021740   \n",
       "1              0.0             0.0  0.452055  0.048052  0.800000  0.000000   \n",
       "2              0.0             0.0  0.287671  0.137581  0.533333  0.000000   \n",
       "3              0.0             0.0  0.493151  0.150486  0.400000  0.000000   \n",
       "4              0.0             0.0  0.150685  0.220635  0.800000  0.000000   \n",
       "...            ...             ...       ...       ...       ...       ...   \n",
       "48837          0.0             0.0  0.301370  0.137428  0.800000  0.000000   \n",
       "48838          0.0             0.0  0.643836  0.209130  0.533333  0.000000   \n",
       "48839          0.0             0.0  0.287671  0.245379  0.800000  0.000000   \n",
       "48840          0.0             0.0  0.369863  0.048444  0.800000  0.054551   \n",
       "48841          0.0             0.0  0.246575  0.114919  0.800000  0.000000   \n",
       "\n",
       "        11        12  \n",
       "0      0.0  0.397959  \n",
       "1      0.0  0.122449  \n",
       "2      0.0  0.397959  \n",
       "3      0.0  0.397959  \n",
       "4      0.0  0.397959  \n",
       "...    ...       ...  \n",
       "48837  0.0  0.357143  \n",
       "48838  0.0  0.397959  \n",
       "48839  0.0  0.500000  \n",
       "48840  0.0  0.397959  \n",
       "48841  0.0  0.602041  \n",
       "\n",
       "[48842 rows x 105 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Датасет без обработки пропусков:')\n",
    "# исходный датасет\n",
    "display(pd.DataFrame(preprocessor_base.transform(X), columns=columns_base))\n",
    "\n",
    "print('Датасет, в котором пропуски (?) заменены на самые частые значения:')\n",
    "# Выведим датасет с предобработанными данными, в котором пропуски (?) заменены на самые частые значения\n",
    "preprocessor_imputer.fit(X)\n",
    "# числовые названия колонок извлекаются с префиксом 'x' - добавим x перед числами в списке имен категорийных колонок\n",
    "categorical_extract = []\n",
    "for i in categorical:\n",
    "    categorical_extract.append('x' + str(i))\n",
    "\n",
    "# извлечем названия создаваемых колонок с помощью OneHotEncoder\n",
    "categorical_columns = preprocessor_imputer.named_transformers_['cat']['encoder'].get_feature_names(categorical_extract)\n",
    "columns_imputer = np.append(categorical_columns, numerical)\n",
    "\n",
    "# датасет, в котором пропуски (?) замнены на самые частые значения\n",
    "display(pd.DataFrame(preprocessor_imputer.transform(X), columns=columns_imputer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "- стало на 3 столбца меньше, так как больше нет значения \"?\";\n",
    "- пропуски были в 3 категорийных столбцах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка данных (? может присутствовать только в текстовых данных)#\n",
    "# добавим в preprocessor для категорийных данных SimpleImputer\n",
    "preprocessor_imputer = ColumnTransformer([('cat', Pipeline([('imputer', SimpleImputer(missing_values='?', strategy=\"most_frequent\")), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                          ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для LogisticRegression (в данных пропуски (?) заменены самыми частыми значениями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy LogisticRegression with SimpleImputer cross_val_score:             0.8507\n",
      "f1 LogisticRegression with SimpleImputer cross_val_score (0 most frequent): 0.6544\n",
      "f1 LogisticRegression with SimpleImputer cross_val_score (1 most frequent): 0.9048\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_LogReg_SimpImp = Pipeline([('preprocessor', preprocessor_imputer), ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "LogReg_SimpImp_accuracy = cross_val_score(pipe_LogReg_SimpImp, X, y, cv=5, scoring='accuracy').mean()\n",
    "LogReg_SimpImp_0mf_f1 = cross_val_score(pipe_LogReg_SimpImp, X, y, cv=5, scoring='f1').mean()\n",
    "LogReg_SimpImp_1mf_f1 = cross_val_score(pipe_LogReg_SimpImp, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy LogisticRegression with SimpleImputer cross_val_score:             {LogReg_SimpImp_accuracy:.4f}\")\n",
    "print(f\"f1 LogisticRegression with SimpleImputer cross_val_score (0 most frequent): {LogReg_SimpImp_0mf_f1:.4f}\")\n",
    "print(f\"f1 LogisticRegression with SimpleImputer cross_val_score (1 most frequent): {LogReg_SimpImp_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для SVC (в данных пропуски (?) заменены самыми частыми значениями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy SVC with SimpleImputer cross_val_score:             0.8395\n",
      "f1 SVC with SimpleImputer cross_val_score (0 most frequent): 0.6167\n",
      "f1 SVC with SimpleImputer cross_val_score (1 most frequent): 0.8985\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_SVC_SimpImp = Pipeline([('preprocessor', preprocessor_imputer), ('classifier', SVC(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "SVC_SimpImp_accuracy = cross_val_score(pipe_SVC_SimpImp, X, y, cv=5, scoring='accuracy').mean()\n",
    "SVC_SimpImp_0mf_f1 = cross_val_score(pipe_SVC_SimpImp, X, y, cv=5, scoring='f1').mean()\n",
    "SVC_SimpImp_1mf_f1 = cross_val_score(pipe_SVC_SimpImp, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy SVC with SimpleImputer cross_val_score:             {SVC_SimpImp_accuracy:.4f}\")\n",
    "print(f\"f1 SVC with SimpleImputer cross_val_score (0 most frequent): {SVC_SimpImp_0mf_f1:.4f}\")\n",
    "print(f\"f1 SVC with SimpleImputer cross_val_score (1 most frequent): {SVC_SimpImp_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для LinearSVC (в данных пропуски (?) заменены самыми частыми значениями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy LinearSVC with SimpleImputer cross_val_score:             0.8513\n",
      "f1 LinearSVC with SimpleImputer cross_val_score (0 most frequent): 0.6519\n",
      "f1 LinearSVC with SimpleImputer cross_val_score (1 most frequent): 0.9054\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_LinSVC_SimpImp = Pipeline([('preprocessor', preprocessor_imputer), ('classifier', LinearSVC(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "LinSVC_SimpImp_accuracy = cross_val_score(pipe_LinSVC_SimpImp, X, y, cv=5, scoring='accuracy').mean()\n",
    "LinSVC_SimpImp_0mf_f1 = cross_val_score(pipe_LinSVC_SimpImp, X, y, cv=5, scoring='f1').mean()\n",
    "LinSVC_SimpImp_1mf_f1 = cross_val_score(pipe_LinSVC_SimpImp, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy LinearSVC with SimpleImputer cross_val_score:             {LinSVC_SimpImp_accuracy:.4f}\")\n",
    "print(f\"f1 LinearSVC with SimpleImputer cross_val_score (0 most frequent): {LinSVC_SimpImp_0mf_f1:.4f}\")\n",
    "print(f\"f1 LinearSVC with SimpleImputer cross_val_score (1 most frequent): {LinSVC_SimpImp_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Algorithmm</th>\n",
       "      <th>Dummy_classifier</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LogisticRegression</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SVC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LinearSVC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_preparation</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760718</td>\n",
       "      <td>0.850907</td>\n",
       "      <td>0.850682</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.852914</td>\n",
       "      <td>0.851255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0_most_frequent</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655816</td>\n",
       "      <td>0.654437</td>\n",
       "      <td>0.620083</td>\n",
       "      <td>0.616722</td>\n",
       "      <td>0.657816</td>\n",
       "      <td>0.651865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1_most_frequent</th>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.904765</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>0.898483</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>0.905422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithmm         Dummy_classifier LogisticRegression                \\\n",
       "Data_preparation        No_modified        No_modified SimpleImputer   \n",
       "accuracy                   0.760718           0.850907      0.850682   \n",
       "f1_0_most_frequent         0.000000           0.655816      0.654437   \n",
       "f1_1_most_frequent         0.864100           0.904843      0.904765   \n",
       "\n",
       "Algorithmm                 SVC                 LinearSVC                \n",
       "Data_preparation   No_modified SimpleImputer No_modified SimpleImputer  \n",
       "accuracy              0.839974      0.839503    0.852914      0.851255  \n",
       "f1_0_most_frequent    0.620083      0.616722    0.657816      0.651865  \n",
       "f1_1_most_frequent    0.898648      0.898483    0.906322      0.905422  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сведем все данные в таблицу\n",
    "cross_val_score_result = pd.DataFrame(data = [[DummyCl_accuracy, LogReg_accuracy, LogReg_SimpImp_accuracy, SVC_accuracy, SVC_SimpImp_accuracy, LinSVC_accuracy, LinSVC_SimpImp_accuracy],\n",
    "                                              [DummyCl_0mf_f1,   LogReg_0mf_f1,   LogReg_SimpImp_0mf_f1,   SVC_0mf_f1,   SVC_SimpImp_0mf_f1,   LinSVC_0mf_f1,   LinSVC_SimpImp_0mf_f1],\n",
    "                                              [DummyCl_1mf_f1,   LogReg_1mf_f1,   LogReg_SimpImp_1mf_f1,   SVC_1mf_f1,   SVC_SimpImp_1mf_f1,   LinSVC_1mf_f1,   LinSVC_SimpImp_1mf_f1]],\n",
    "                                      index = ['accuracy', 'f1_0_most_frequent', 'f1_1_most_frequent'],\n",
    "                                      columns = pd.MultiIndex.from_tuples([('Dummy_classifier', 'No_modified'),\n",
    "                                                                           ('LogisticRegression', 'No_modified'), ('LogisticRegression', 'SimpleImputer'),\n",
    "                                                                           ('SVC', 'No_modified'), ('SVC', 'SimpleImputer'),\n",
    "                                                                           ('LinearSVC', 'No_modified'), ('LinearSVC', 'SimpleImputer'),\n",
    "                                                                          ],\n",
    "                                                                          names=['Algorithmm', 'Data_preparation']))\n",
    "cross_val_score_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: замена пропущенных значений на самые частые несколько ухудшило метрики для рассмотренных алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для избежания перекоса индексов в X и y нужно в исходном датасете удалить строки, содержащие '?' и заново разбить его на признаки и целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1       2          3   4                   5   \\\n",
       "48839  38       Private  374983  Bachelors  13  Married-civ-spouse   \n",
       "48840  44       Private   83891  Bachelors  13            Divorced   \n",
       "48841  35  Self-emp-inc  182148  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                    6          7                   8     9     10  11  12  \\\n",
       "48839   Prof-specialty    Husband               White  Male     0   0  50   \n",
       "48840     Adm-clerical  Own-child  Asian-Pac-Islander  Male  5455   0  40   \n",
       "48841  Exec-managerial    Husband               White  Male     0   0  60   \n",
       "\n",
       "                  13  \n",
       "48839  United-States  \n",
       "48840  United-States  \n",
       "48841  United-States  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменим знак ? на NaN и удалим строки, содержащие хотя бы 1 пропуск\n",
    "# создадим копию датафрейма без целевой переменной (признаки)\n",
    "X_dropna = data.replace({'?': np.nan}).dropna().loc[:,0:13].copy()\n",
    "X_dropna.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    34014\n",
       "1    11208\n",
       "Name: 14, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменим знак ? на NaN и удалим строки, содержащие хотя бы 1 пропуск\n",
    "# создадим копию столбца 14 датафрейма (целевая переменная)\n",
    "y_dropna = data.replace({'?': np.nan}).dropna()[14].copy()\n",
    "# заменим значения менее 50к на 0, значения более 50к на 1\n",
    "y_dropna[y_dropna == '<=50K'] = 0\n",
    "y_dropna[y_dropna == '>50K'] = 1\n",
    "# преобразуем тип данных целевой переменной в int\n",
    "y_dropna = y_dropna.astype(int)\n",
    "y_dropna.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1       2          3   4                   5   \\\n",
       "48839  38       Private  374983  Bachelors  13  Married-civ-spouse   \n",
       "48840  44       Private   83891  Bachelors  13            Divorced   \n",
       "48841  35  Self-emp-inc  182148  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                    6          7                   8     9     10  11  12  \\\n",
       "48839   Prof-specialty    Husband               White  Male     0   0  50   \n",
       "48840     Adm-clerical  Own-child  Asian-Pac-Islander  Male  5455   0  40   \n",
       "48841  Exec-managerial    Husband               White  Male     0   0  60   \n",
       "\n",
       "                  13  \n",
       "48839  United-States  \n",
       "48840  United-States  \n",
       "48841  United-States  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    34014\n",
       "1    11208\n",
       "Name: 14, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# альтернативная запись - короче код, но дольше выполняется\n",
    "# определим индексы строк, в которых нет пропуска (?)\n",
    "index_notnan = (X != '?').all(axis=1)\n",
    "# создадим копии X и y со строками без пропусков\n",
    "X_dropna = X[index_notnan]\n",
    "y_dropna = y[index_notnan]\n",
    "display(X_dropna.tail(3))\n",
    "display(y_dropna.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для LogisticRegression (в данных строки с пропусками (?) удалены)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy LogisticRegression with DropNA cross_val_score:             0.8468\n",
      "f1 LogisticRegression with DropNA cross_val_score (0 most frequent): 0.6602\n",
      "f1 LogisticRegression with DropNA cross_val_score (1 most frequent): 0.9011\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_LogReg_DropNA = Pipeline([('preprocessor', preprocessor_base), ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "LogReg_DropNA_accuracy = cross_val_score(pipe_LogReg_DropNA, X_dropna, y_dropna, cv=5, scoring='accuracy').mean()\n",
    "LogReg_DropNA_0mf_f1 = cross_val_score(pipe_LogReg_DropNA, X_dropna, y_dropna, cv=5, scoring='f1').mean()\n",
    "LogReg_DropNA_1mf_f1 = cross_val_score(pipe_LogReg_DropNA, X_dropna, abs(y_dropna-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy LogisticRegression with DropNA cross_val_score:             {LogReg_DropNA_accuracy:.4f}\")\n",
    "print(f\"f1 LogisticRegression with DropNA cross_val_score (0 most frequent): {LogReg_DropNA_0mf_f1:.4f}\")\n",
    "print(f\"f1 LogisticRegression with DropNA cross_val_score (1 most frequent): {LogReg_DropNA_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для SVC (в данных строки с пропусками (?) удалены)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy SVC with DropNA cross_val_score:             0.8357\n",
      "f1 SVC with DropNA cross_val_score (0 most frequent): 0.6267\n",
      "f1 SVC with DropNA cross_val_score (1 most frequent): 0.8947\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_SVC_DropNA = Pipeline([('preprocessor', preprocessor_base), ('classifier', SVC(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "SVC_DropNA_accuracy = cross_val_score(pipe_SVC_DropNA, X_dropna, y_dropna, cv=5, scoring='accuracy').mean()\n",
    "SVC_DropNA_0mf_f1 = cross_val_score(pipe_SVC_DropNA, X_dropna, y_dropna, cv=5, scoring='f1').mean()\n",
    "SVC_DropNA_1mf_f1 = cross_val_score(pipe_SVC_DropNA, X_dropna, abs(y_dropna-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy SVC with DropNA cross_val_score:             {SVC_DropNA_accuracy:.4f}\")\n",
    "print(f\"f1 SVC with DropNA cross_val_score (0 most frequent): {SVC_DropNA_0mf_f1:.4f}\")\n",
    "print(f\"f1 SVC with DropNA cross_val_score (1 most frequent): {SVC_DropNA_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для LinearSVC (в данных строки с пропусками (?) удалены)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy LinearSVC with DropNA cross_val_score:             0.8485\n",
      "f1 LinearSVC with DropNA cross_val_score (0 most frequent): 0.6616\n",
      "f1 LinearSVC with DropNA cross_val_score (1 most frequent): 0.9024\n"
     ]
    }
   ],
   "source": [
    "# создание пайплайна\n",
    "pipe_LinSVC_DropNA = Pipeline([('preprocessor', preprocessor_base), ('classifier', LinearSVC(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "LinSVC_DropNA_accuracy = cross_val_score(pipe_LinSVC_DropNA, X_dropna, y_dropna, cv=5, scoring='accuracy').mean()\n",
    "LinSVC_DropNA_0mf_f1 = cross_val_score(pipe_LinSVC_DropNA, X_dropna, y_dropna, cv=5, scoring='f1').mean()\n",
    "LinSVC_DropNA_1mf_f1 = cross_val_score(pipe_LinSVC_DropNA, X_dropna, abs(y_dropna-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy LinearSVC with DropNA cross_val_score:             {LinSVC_DropNA_accuracy:.4f}\")\n",
    "print(f\"f1 LinearSVC with DropNA cross_val_score (0 most frequent): {LinSVC_DropNA_0mf_f1:.4f}\")\n",
    "print(f\"f1 LinearSVC with DropNA cross_val_score (1 most frequent): {LinSVC_DropNA_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Algorithmm</th>\n",
       "      <th>Dummy_classifier</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LogisticRegression</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LinearSVC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_preparation</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760718</td>\n",
       "      <td>0.850907</td>\n",
       "      <td>0.850682</td>\n",
       "      <td>0.846845</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.852914</td>\n",
       "      <td>0.851255</td>\n",
       "      <td>0.848503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0_most_frequent</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655816</td>\n",
       "      <td>0.654437</td>\n",
       "      <td>0.660159</td>\n",
       "      <td>0.620083</td>\n",
       "      <td>0.616722</td>\n",
       "      <td>0.626712</td>\n",
       "      <td>0.657816</td>\n",
       "      <td>0.651865</td>\n",
       "      <td>0.661613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1_most_frequent</th>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.904765</td>\n",
       "      <td>0.901146</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>0.898483</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>0.905422</td>\n",
       "      <td>0.902403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithmm         Dummy_classifier LogisticRegression                \\\n",
       "Data_preparation        No_modified        No_modified SimpleImputer   \n",
       "accuracy                   0.760718           0.850907      0.850682   \n",
       "f1_0_most_frequent         0.000000           0.655816      0.654437   \n",
       "f1_1_most_frequent         0.864100           0.904843      0.904765   \n",
       "\n",
       "Algorithmm                           SVC                           LinearSVC  \\\n",
       "Data_preparation      DropNA No_modified SimpleImputer    DropNA No_modified   \n",
       "accuracy            0.846845    0.839974      0.839503  0.835700    0.852914   \n",
       "f1_0_most_frequent  0.660159    0.620083      0.616722  0.626712    0.657816   \n",
       "f1_1_most_frequent  0.901146    0.898648      0.898483  0.894667    0.906322   \n",
       "\n",
       "Algorithmm                                  \n",
       "Data_preparation   SimpleImputer    DropNA  \n",
       "accuracy                0.851255  0.848503  \n",
       "f1_0_most_frequent      0.651865  0.661613  \n",
       "f1_1_most_frequent      0.905422  0.902403  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сведем все данные в таблицу\n",
    "cross_val_score_result = pd.DataFrame(data = [[DummyCl_accuracy, LogReg_accuracy, LogReg_SimpImp_accuracy, LogReg_DropNA_accuracy, SVC_accuracy, SVC_SimpImp_accuracy, SVC_DropNA_accuracy, LinSVC_accuracy, LinSVC_SimpImp_accuracy, LinSVC_DropNA_accuracy],\n",
    "                                              [DummyCl_0mf_f1,   LogReg_0mf_f1,   LogReg_SimpImp_0mf_f1,   LogReg_DropNA_0mf_f1,   SVC_0mf_f1,   SVC_SimpImp_0mf_f1,   SVC_DropNA_0mf_f1,   LinSVC_0mf_f1,   LinSVC_SimpImp_0mf_f1,   LinSVC_DropNA_0mf_f1],\n",
    "                                              [DummyCl_1mf_f1,   LogReg_1mf_f1,   LogReg_SimpImp_1mf_f1,   LogReg_DropNA_1mf_f1,   SVC_1mf_f1,   SVC_SimpImp_1mf_f1,   SVC_DropNA_1mf_f1,   LinSVC_1mf_f1,   LinSVC_SimpImp_1mf_f1,   LinSVC_DropNA_1mf_f1]],\n",
    "                                      index = ['accuracy', 'f1_0_most_frequent', 'f1_1_most_frequent'],\n",
    "                                      columns = pd.MultiIndex.from_tuples([('Dummy_classifier', 'No_modified'),\n",
    "                                                                           ('LogisticRegression', 'No_modified'), ('LogisticRegression', 'SimpleImputer'), ('LogisticRegression', 'DropNA'),\n",
    "                                                                           ('SVC', 'No_modified'), ('SVC', 'SimpleImputer'), ('SVC', 'DropNA'),\n",
    "                                                                           ('LinearSVC', 'No_modified'), ('LinearSVC', 'SimpleImputer'), ('LinearSVC', 'DropNA'),\n",
    "                                                                          ],\n",
    "                                                                          names=['Algorithmm', 'Data_preparation']))\n",
    "cross_val_score_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- удаление данных, содержащих пропуски, незначительно ухудшило метрики для рассмотренных алгоритмов;\n",
    "- при этом метрика f1 для данных, в котором наиболее частое значение 0, немного улучшилась для рассмотренных алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score для RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy RandomForestClassifier cross_val_score:             0.8526\n",
      "f1 RandomForestClassifier cross_val_score (0 most frequent): 0.6666\n",
      "f1 RandomForestClassifier cross_val_score (1 most frequent): 0.9047\n"
     ]
    }
   ],
   "source": [
    "# на исходных данных\n",
    "\n",
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "                                  \n",
    "# создание пайплайна\n",
    "pipe_RandFrst = Pipeline([('preprocessor', preprocessor_base), ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "RandFrst_accuracy = cross_val_score(pipe_RandFrst, X, y, cv=5, scoring='accuracy').mean()\n",
    "RandFrst_0mf_f1 = cross_val_score(pipe_RandFrst, X, y, cv=5, scoring='f1').mean()\n",
    "RandFrst_1mf_f1 = cross_val_score(pipe_RandFrst, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy RandomForestClassifier cross_val_score:             {RandFrst_accuracy:.4f}\")\n",
    "print(f\"f1 RandomForestClassifier cross_val_score (0 most frequent): {RandFrst_0mf_f1:.4f}\")\n",
    "print(f\"f1 RandomForestClassifier cross_val_score (1 most frequent): {RandFrst_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy RandomForestClassifier with SimpleImputer cross_val_score:             0.8533\n",
      "f1 RandomForestClassifier with SimpleImputer cross_val_score (0 most frequent): 0.6684\n",
      "f1 RandomForestClassifier with SimpleImputer cross_val_score (1 most frequent): 0.9050\n"
     ]
    }
   ],
   "source": [
    "# на данных, в которых пропуски (?) заполнены сымым частым значением\n",
    "\n",
    "# предобработка данных (? может присутствовать только в текстовых данных)#\n",
    "# добавим в preprocessor для категорийных данных SimpleImputer\n",
    "preprocessor_imputer = ColumnTransformer([('cat', Pipeline([('SimpleImputer', SimpleImputer(missing_values='?', strategy=\"most_frequent\")), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "\n",
    "# создание пайплайна\n",
    "pipe_RandFrst_SimpImp = Pipeline([('preprocessor', preprocessor_imputer), ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "RandFrst_SimpImp_accuracy = cross_val_score(pipe_RandFrst_SimpImp, X, y, cv=5, scoring='accuracy').mean()\n",
    "RandFrst_SimpImp_0mf_f1 = cross_val_score(pipe_RandFrst_SimpImp, X, y, cv=5, scoring='f1').mean()\n",
    "RandFrst_SimpImp_1mf_f1 = cross_val_score(pipe_RandFrst_SimpImp, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy RandomForestClassifier with SimpleImputer cross_val_score:             {RandFrst_SimpImp_accuracy:.4f}\")\n",
    "print(f\"f1 RandomForestClassifier with SimpleImputer cross_val_score (0 most frequent): {RandFrst_SimpImp_0mf_f1:.4f}\")\n",
    "print(f\"f1 RandomForestClassifier with SimpleImputer cross_val_score (1 most frequent): {RandFrst_SimpImp_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy RandomForestClassifier with DropNA cross_val_score:             0.8490\n",
      "f1 RandomForestClassifier with DropNA cross_val_score (0 most frequent): 0.6726\n",
      "f1 RandomForestClassifier with DropNA cross_val_score (1 most frequent): 0.9013\n"
     ]
    }
   ],
   "source": [
    "# на данных, в которых строки с пропусками (?) удалены\n",
    "\n",
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "                                  \n",
    "# создание пайплайна\n",
    "pipe_RandFrst_DropNA = Pipeline([('preprocessor', preprocessor_base), ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "RandFrst_DropNA_accuracy = cross_val_score(pipe_RandFrst_DropNA, X_dropna, y_dropna, cv=5, scoring='accuracy').mean()\n",
    "RandFrst_DropNA_0mf_f1 = cross_val_score(pipe_RandFrst_DropNA, X_dropna, y_dropna, cv=5, scoring='f1').mean()\n",
    "RandFrst_DropNA_1mf_f1 = cross_val_score(pipe_RandFrst_DropNA, X_dropna, abs(y_dropna-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy RandomForestClassifier with DropNA cross_val_score:             {RandFrst_DropNA_accuracy:.4f}\")\n",
    "print(f\"f1 RandomForestClassifier with DropNA cross_val_score (0 most frequent): {RandFrst_DropNA_0mf_f1:.4f}\")\n",
    "print(f\"f1 RandomForestClassifier with DropNA cross_val_score (1 most frequent): {RandFrst_DropNA_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score для GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy GradientBoostingClassifier cross_val_score:             0.8676\n",
      "f1 GradientBoostingClassifier cross_val_score (0 most frequent): 0.6869\n",
      "f1 GradientBoostingClassifier cross_val_score (1 most frequent): 0.9160\n"
     ]
    }
   ],
   "source": [
    "# на исходных данных\n",
    "\n",
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "                                  \n",
    "# создание пайплайна\n",
    "pipe_GradBst = Pipeline([('preprocessor', preprocessor_base), ('classifier', GradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "GradBst_accuracy = cross_val_score(pipe_GradBst, X, y, cv=5, scoring='accuracy').mean()\n",
    "GradBst_0mf_f1 = cross_val_score(pipe_GradBst, X, y, cv=5, scoring='f1').mean()\n",
    "GradBst_1mf_f1 = cross_val_score(pipe_GradBst, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy GradientBoostingClassifier cross_val_score:             {GradBst_accuracy:.4f}\")\n",
    "print(f\"f1 GradientBoostingClassifier cross_val_score (0 most frequent): {GradBst_0mf_f1:.4f}\")\n",
    "print(f\"f1 GradientBoostingClassifier cross_val_score (1 most frequent): {GradBst_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy GradientBoostingClassifier with SimpleImputer cross_val_score:             0.8666\n",
      "f1 GradientBoostingClassifier with SimpleImputer cross_val_score (0 most frequent): 0.6832\n",
      "f1 GradientBoostingClassifier with SimpleImputer cross_val_score (1 most frequent): 0.9155\n"
     ]
    }
   ],
   "source": [
    "# на данных, в которых пропуски (?) заполнены сымым частым значением\n",
    "\n",
    "# предобработка данных (? может присутствовать только в текстовых данных)#\n",
    "# добавим в preprocessor для категорийных данных SimpleImputer\n",
    "preprocessor_imputer = ColumnTransformer([('cat', Pipeline([('SimpleImputer', SimpleImputer(missing_values='?', strategy=\"most_frequent\")), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "\n",
    "# создание пайплайна\n",
    "pipe_GradBst_SimpImp = Pipeline([('preprocessor', preprocessor_imputer), ('classifier', GradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "GradBst_SimpImp_accuracy = cross_val_score(pipe_GradBst_SimpImp, X, y, cv=5, scoring='accuracy').mean()\n",
    "GradBst_SimpImp_0mf_f1 = cross_val_score(pipe_GradBst_SimpImp, X, y, cv=5, scoring='f1').mean()\n",
    "GradBst_SimpImp_1mf_f1 = cross_val_score(pipe_GradBst_SimpImp, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy GradientBoostingClassifier with SimpleImputer cross_val_score:             {GradBst_SimpImp_accuracy:.4f}\")\n",
    "print(f\"f1 GradientBoostingClassifier with SimpleImputer cross_val_score (0 most frequent): {GradBst_SimpImp_0mf_f1:.4f}\")\n",
    "print(f\"f1 GradientBoostingClassifier with SimpleImputer cross_val_score (1 most frequent): {GradBst_SimpImp_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy GradientBoostingClassifier with DropNA cross_val_score:             0.8629\n",
      "f1 GradientBoostingClassifier with DropNA cross_val_score (0 most frequent): 0.6871\n",
      "f1 GradientBoostingClassifier with DropNA cross_val_score (1 most frequent): 0.9123\n"
     ]
    }
   ],
   "source": [
    "# на данных, в которых строки с пропусками (?) удалены\n",
    "\n",
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "                                  \n",
    "# создание пайплайна\n",
    "pipe_GradBst_DropNA = Pipeline([('preprocessor', preprocessor_base), ('classifier', GradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "GradBst_DropNA_accuracy = cross_val_score(pipe_GradBst_DropNA, X_dropna, y_dropna, cv=5, scoring='accuracy').mean()\n",
    "GradBst_DropNA_0mf_f1 = cross_val_score(pipe_GradBst_DropNA, X_dropna, y_dropna, cv=5, scoring='f1').mean()\n",
    "GradBst_DropNA_1mf_f1 = cross_val_score(pipe_GradBst_DropNA, X_dropna, abs(y_dropna-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy GradientBoostingClassifier with DropNA cross_val_score:             {GradBst_DropNA_accuracy:.4f}\")\n",
    "print(f\"f1 GradientBoostingClassifier with DropNA cross_val_score (0 most frequent): {GradBst_DropNA_0mf_f1:.4f}\")\n",
    "print(f\"f1 GradientBoostingClassifier with DropNA cross_val_score (1 most frequent): {GradBst_DropNA_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Dummy_classifier</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LogisticRegression</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LinearSVC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RandomForestClassifier</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GradientBoostingClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_preparation</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760718</td>\n",
       "      <td>0.850907</td>\n",
       "      <td>0.850682</td>\n",
       "      <td>0.846845</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.852914</td>\n",
       "      <td>0.851255</td>\n",
       "      <td>0.848503</td>\n",
       "      <td>0.852565</td>\n",
       "      <td>0.853303</td>\n",
       "      <td>0.848967</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.866590</td>\n",
       "      <td>0.862943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0_most_frequent</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655816</td>\n",
       "      <td>0.654437</td>\n",
       "      <td>0.660159</td>\n",
       "      <td>0.620083</td>\n",
       "      <td>0.616722</td>\n",
       "      <td>0.626712</td>\n",
       "      <td>0.657816</td>\n",
       "      <td>0.651865</td>\n",
       "      <td>0.661613</td>\n",
       "      <td>0.666582</td>\n",
       "      <td>0.668446</td>\n",
       "      <td>0.672592</td>\n",
       "      <td>0.686905</td>\n",
       "      <td>0.683188</td>\n",
       "      <td>0.687097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1_most_frequent</th>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.904765</td>\n",
       "      <td>0.901146</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>0.898483</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>0.905422</td>\n",
       "      <td>0.902403</td>\n",
       "      <td>0.904750</td>\n",
       "      <td>0.905036</td>\n",
       "      <td>0.901342</td>\n",
       "      <td>0.916026</td>\n",
       "      <td>0.915502</td>\n",
       "      <td>0.912252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm          Dummy_classifier LogisticRegression                \\\n",
       "Data_preparation        No_modified        No_modified SimpleImputer   \n",
       "accuracy                   0.760718           0.850907      0.850682   \n",
       "f1_0_most_frequent         0.000000           0.655816      0.654437   \n",
       "f1_1_most_frequent         0.864100           0.904843      0.904765   \n",
       "\n",
       "Algorithm                            SVC                           LinearSVC  \\\n",
       "Data_preparation      DropNA No_modified SimpleImputer    DropNA No_modified   \n",
       "accuracy            0.846845    0.839974      0.839503  0.835700    0.852914   \n",
       "f1_0_most_frequent  0.660159    0.620083      0.616722  0.626712    0.657816   \n",
       "f1_1_most_frequent  0.901146    0.898648      0.898483  0.894667    0.906322   \n",
       "\n",
       "Algorithm                                  RandomForestClassifier  \\\n",
       "Data_preparation   SimpleImputer    DropNA            No_modified   \n",
       "accuracy                0.851255  0.848503               0.852565   \n",
       "f1_0_most_frequent      0.651865  0.661613               0.666582   \n",
       "f1_1_most_frequent      0.905422  0.902403               0.904750   \n",
       "\n",
       "Algorithm                                  GradientBoostingClassifier  \\\n",
       "Data_preparation   SimpleImputer    DropNA                No_modified   \n",
       "accuracy                0.853303  0.848967                   0.867573   \n",
       "f1_0_most_frequent      0.668446  0.672592                   0.686905   \n",
       "f1_1_most_frequent      0.905036  0.901342                   0.916026   \n",
       "\n",
       "Algorithm                                   \n",
       "Data_preparation   SimpleImputer    DropNA  \n",
       "accuracy                0.866590  0.862943  \n",
       "f1_0_most_frequent      0.683188  0.687097  \n",
       "f1_1_most_frequent      0.915502  0.912252  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сведем все результаты в таблицу\n",
    "cross_val_score_result = pd.DataFrame(data = [[DummyCl_accuracy, LogReg_accuracy, LogReg_SimpImp_accuracy, LogReg_DropNA_accuracy, SVC_accuracy, SVC_SimpImp_accuracy, SVC_DropNA_accuracy, LinSVC_accuracy, LinSVC_SimpImp_accuracy, LinSVC_DropNA_accuracy, RandFrst_accuracy, RandFrst_SimpImp_accuracy, RandFrst_DropNA_accuracy, GradBst_accuracy, GradBst_SimpImp_accuracy, GradBst_DropNA_accuracy],\n",
    "                                              [DummyCl_0mf_f1,   LogReg_0mf_f1,   LogReg_SimpImp_0mf_f1,   LogReg_DropNA_0mf_f1,   SVC_0mf_f1,   SVC_SimpImp_0mf_f1,   SVC_DropNA_0mf_f1,   LinSVC_0mf_f1,   LinSVC_SimpImp_0mf_f1,   LinSVC_DropNA_0mf_f1, RandFrst_0mf_f1,   RandFrst_SimpImp_0mf_f1,   RandFrst_DropNA_0mf_f1,   GradBst_0mf_f1, GradBst_SimpImp_0mf_f1, GradBst_DropNA_0mf_f1],\n",
    "                                              [DummyCl_1mf_f1,   LogReg_1mf_f1,   LogReg_SimpImp_1mf_f1,   LogReg_DropNA_1mf_f1,   SVC_1mf_f1,   SVC_SimpImp_1mf_f1,   SVC_DropNA_1mf_f1,   LinSVC_1mf_f1,   LinSVC_SimpImp_1mf_f1,   LinSVC_DropNA_1mf_f1, RandFrst_1mf_f1,   RandFrst_SimpImp_1mf_f1,   RandFrst_DropNA_1mf_f1,   GradBst_1mf_f1, GradBst_SimpImp_1mf_f1, GradBst_DropNA_1mf_f1]],\n",
    "                                      index = ['accuracy', 'f1_0_most_frequent', 'f1_1_most_frequent'],\n",
    "                                      columns = pd.MultiIndex.from_tuples([('Dummy_classifier', 'No_modified'),\n",
    "                                                                           ('LogisticRegression', 'No_modified'), ('LogisticRegression', 'SimpleImputer'), ('LogisticRegression', 'DropNA'),\n",
    "                                                                           ('SVC', 'No_modified'), ('SVC', 'SimpleImputer'), ('SVC', 'DropNA'),\n",
    "                                                                           ('LinearSVC', 'No_modified'), ('LinearSVC', 'SimpleImputer'), ('LinearSVC', 'DropNA'),\n",
    "                                                                           ('RandomForestClassifier', 'No_modified'), ('RandomForestClassifier', 'SimpleImputer'), ('RandomForestClassifier', 'DropNA'),\n",
    "                                                                           ('GradientBoostingClassifier', 'No_modified'), ('GradientBoostingClassifier', 'SimpleImputer'), ('GradientBoostingClassifier', 'DropNA'),\n",
    "                                                                          ],\n",
    "                                                                          names=['Algorithm', 'Data_preparation']))\n",
    "cross_val_score_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: лучшие метрики получены при использовании GradientBoostingClassifier без обработки пропущенных значений (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попытка написать функцию по удалению строк с пропусками из датасета для пайплайна\n",
    "# функция не заработала - transform удаляет строки в X, а в y - нет и возникает ошибка\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "class Drop_str_NA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._estimator = PowerTransformer()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        index_notnan = (X != '?').all(axis=1)\n",
    "        X_copy = X[index_notnan]\n",
    "        y_copy = y[index_notnan]\n",
    "        return self._estimator.transform(X_copy, y_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм выбора наилучшей модели (подбора параметров)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка данных\n",
    "preprocessor_imputer = ColumnTransformer([('cat', Pipeline([('imputer', SimpleImputer(missing_values='?', strategy=\"most_frequent\")), ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                  ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                  ])\n",
    "\n",
    "# методы кодирования признаков\n",
    "encoders = [OneHotEncoder(handle_unknown='ignore'),\n",
    "            LabelEncoder()\n",
    "            ]\n",
    "# методы масштабирования признаков\n",
    "scalers = [StandardScaler(), MinMaxScaler()]\n",
    "# рассматриваемые модели\n",
    "models = [LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "          SVC(random_state=RANDOM_STATE),\n",
    "          LinearSVC(random_state=RANDOM_STATE),\n",
    "          RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "          GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "          ]\n",
    "\n",
    "search_model = Pipeline(steps=[('preprocessor', preprocessor_imputer), ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))])\n",
    "# Задание параметров\n",
    "params = {\n",
    "          'preprocessor__cat__imputer__strategy': ['mean','median','most_frequent', 'constant'],\n",
    "          'preprocessor__cat__encoder': encoders,\n",
    "          'preprocessor__num': scalers,\n",
    "          'classifier': models\n",
    "}\n",
    "\n",
    "BestModel_SimpImp = GridSearchCV(search_model,\n",
    "                                 param_grid=params,\n",
    "                                 scoring=('accuracy', 'f1'),\n",
    "                                 refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(random_state=42),\n",
       " 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessor__cat__imputer__strategy': 'constant',\n",
       " 'preprocessor__num': StandardScaler()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy best model (0 most frequent): 0.8758\n",
      "f1 best model (0 most frequent):       0.7125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(random_state=42),\n",
       " 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessor__cat__imputer__strategy': 'constant',\n",
       " 'preprocessor__num': StandardScaler()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy best model (1 most frequent): 0.8758\n",
      "f1 best model (1 most frequent):       0.9208\n"
     ]
    }
   ],
   "source": [
    "# Подбор наилучшей модели (параметоров) для случая, когда самое частое значение целевой переменной 0 (<=50K -> 0; >50K -> 1) - соответствует исходному y\n",
    "# Разбиваем выборку на обучающую и тестовую с помощью функции train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=RANDOM_STATE)  # добавляем random stete для повторяемости результата\n",
    "# Обучаем модель\n",
    "BestModel_SimpImp.fit(X_test, y_test)\n",
    "# Посчитаем метрики accurancy и f1 для лучшей модели\n",
    "BestModel_SimpImp_0mf_tst_accuracy = accuracy_score(y_test, BestModel_SimpImp.predict(X_test))\n",
    "BestModel_SimpImp_0mf_tst_f1 = f1_score(y_test, BestModel_SimpImp.predict(X_test))\n",
    "\n",
    "# Подбор наилучшей модели (параметоров) для случая, когда самое частое значение целевой переменной 1 (<=50K -> 1; >50K -> 0) - соответствует инвертированному y (abs(y-1))\n",
    "# Разбиваем выборку на обучающую и тестовую с помощью функции train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, abs(y-1), train_size=0.8, random_state=RANDOM_STATE)  # добавляем random stete для повторяемости результата\n",
    "# Обучаем модель\n",
    "BestModel_SimpImp.fit(X_test, y_test)\n",
    "# Посчитаем метрики accurancy и f1 для лучшей модели\n",
    "BestModel_SimpImp_1mf_tst_accuracy = accuracy_score(y_test, BestModel_SimpImp.predict(X_test))\n",
    "BestModel_SimpImp_1mf_tst_f1 = f1_score(y_test, BestModel_SimpImp.predict(X_test))\n",
    "\n",
    "# Выведем параметры лучшей модули, метрики accurancy и f1\n",
    "display(BestModel_SimpImp.best_params_)\n",
    "print(f\"accuracy best model (0 most frequent): {BestModel_SimpImp_0mf_tst_accuracy:.4f}\")\n",
    "print(f\"f1 best model (0 most frequent):       {BestModel_SimpImp_0mf_tst_f1:.4f}\")\n",
    "display(BestModel_SimpImp.best_params_)\n",
    "print(f\"accuracy best model (1 most frequent): {BestModel_SimpImp_1mf_tst_accuracy:.4f}\")\n",
    "print(f\"f1 best model (1 most frequent):       {BestModel_SimpImp_1mf_tst_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм выбора наилучшей модели (подбора параметров) без обработки пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предобработка данных\n",
    "preprocessor_base = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))]), categorical),\n",
    "                                       ('num', Pipeline([('scaler', MinMaxScaler())]), numerical)\n",
    "                                       ])\n",
    "\n",
    "# методы кодирования признаков\n",
    "encoders = [OneHotEncoder(handle_unknown='ignore'),\n",
    "            LabelEncoder()\n",
    "            ]\n",
    "# методы масштабирования признаков\n",
    "scalers = [StandardScaler(), MinMaxScaler()]\n",
    "# рассматриваемые модели\n",
    "models = [LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),\n",
    "          SVC(random_state=RANDOM_STATE),\n",
    "          LinearSVC(random_state=RANDOM_STATE),\n",
    "          RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "          GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "          ]\n",
    "\n",
    "search_model = Pipeline(steps=[('preprocessor', preprocessor_base), ('classifier', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))])\n",
    "# Задание параметров\n",
    "params = {\n",
    "          'preprocessor__cat__encoder': encoders,\n",
    "          'preprocessor__num': scalers,\n",
    "          'classifier': models\n",
    "          }\n",
    "\n",
    "BestModel = GridSearchCV(search_model,\n",
    "                         param_grid=params,\n",
    "                         scoring=('accuracy', 'f1'),\n",
    "                         refit='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(random_state=42),\n",
       " 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessor__num': StandardScaler()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy best model (0 most frequent): 0.8758\n",
      "f1 best model (0 most frequent):       0.7125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier': GradientBoostingClassifier(random_state=42),\n",
       " 'preprocessor__cat__encoder': OneHotEncoder(handle_unknown='ignore'),\n",
       " 'preprocessor__num': StandardScaler()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy best model (1 most frequent): 0.8758\n",
      "f1 best model (1 most frequent):       0.9208\n"
     ]
    }
   ],
   "source": [
    "# Подбор наилучшей модели (параметоров) для случая, когда самое частое значение целевой переменной 0 (<=50K -> 0; >50K -> 1) - соответствует исходному y\n",
    "# Разбиваем выборку на обучающую и тестовую с помощью функции train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=RANDOM_STATE)  # добавляем random stete для повторяемости результата\n",
    "# Обучаем модель\n",
    "BestModel.fit(X_test, y_test)\n",
    "# Посчитаем метрики accurancy и f1 для лучшей модели\n",
    "BestModel_0mf_tst_accuracy = accuracy_score(y_test, BestModel.predict(X_test))\n",
    "BestModel_0mf_tst_f1 = f1_score(y_test, BestModel.predict(X_test))\n",
    "\n",
    "# Подбор наилучшей модели (параметоров) для случая, когда самое частое значение целевой переменной 1 (<=50K -> 1; >50K -> 0) - соответствует инвертированному y (abs(y-1))\n",
    "# Разбиваем выборку на обучающую и тестовую с помощью функции train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, abs(y-1), train_size=0.8, random_state=RANDOM_STATE)  # добавляем random stete для повторяемости результата\n",
    "# Обучаем модель\n",
    "BestModel.fit(X_test, y_test)\n",
    "# Посчитаем метрики accurancy и f1 для лучшей модели\n",
    "BestModel_1mf_tst_accuracy = accuracy_score(y_test, BestModel.predict(X_test))\n",
    "BestModel_1mf_tst_f1 = f1_score(y_test, BestModel.predict(X_test))\n",
    "\n",
    "# Выведем параметры лучшей модули, метрики accurancy и f1\n",
    "display(BestModel.best_params_)\n",
    "print(f\"accuracy best model (0 most frequent): {BestModel_0mf_tst_accuracy:.4f}\")\n",
    "print(f\"f1 best model (0 most frequent):       {BestModel_0mf_tst_f1:.4f}\")\n",
    "# Выведем параметры лучшей модули, метрики accurancy и f1\n",
    "display(BestModel.best_params_)\n",
    "print(f\"accuracy best model (1 most frequent): {BestModel_1mf_tst_accuracy:.4f}\")\n",
    "print(f\"f1 best model (1 most frequent):       {BestModel_1mf_tst_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшими параметрами модели оказались:\n",
    "- модель: GradientBoostingClassifier\n",
    "- метод масштабирование признаков: StandardScaler;\n",
    "- метод кодирования признаков: OneHotEncoder;\n",
    "- заполнение пропусков константой либо без заполнения пропусков (видимо, замена \"?\" на другую константу сути пропуска не меняет)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- параметры модели в данном случае не зависят от самого частого значения целевой переменной;\n",
    "- метрика accuracy в данном случае не зависят от самого частого значения целевой переменной (0.8758);\n",
    "- метрика f1 зависит от самого частого значения целевой переменной: (0.7125 при самом частом значении 0 и 0.9208 при самом частом значении 1);\n",
    "- значения метрик существенно лучше при подборе параметров модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем cross_val_score для лучшей модели по метрикам accuracy и f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy best model cross_val_score:             0.8676\n",
      "f1 best model cross_val_score (0 most frequent): 0.6869\n",
      "f1 best model cross_val_score (1 most frequent): 0.9160\n"
     ]
    }
   ],
   "source": [
    "# без обработки пропусков\n",
    "\n",
    "# предобработка данных\n",
    "preprocessor_best = ColumnTransformer([('cat', Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore'))]), categorical),\n",
    "                                       ('num', Pipeline([('scaler', StandardScaler())]), numerical)\n",
    "                                       ])\n",
    "                                  \n",
    "# создание пайплайна\n",
    "pipe_GradBst = Pipeline([('preprocessor', preprocessor_best), ('classifier', GradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "# расчет cross_val_score по метрикам accurancy и f1\n",
    "BestModel_1mf_accuracy = cross_val_score(pipe_GradBst, X, y, cv=5, scoring='accuracy').mean()\n",
    "BestModel_0mf_f1 = cross_val_score(pipe_GradBst, X, y, cv=5, scoring='f1').mean()\n",
    "BestModel_1mf_f1 = cross_val_score(pipe_GradBst, X, abs(y-1), cv=5, scoring='f1').mean()\n",
    "\n",
    "# вывод cross_val_score по метрикам accurancy и f1\n",
    "print(f\"accuracy best model cross_val_score:             {BestModel_1mf_accuracy:.4f}\")\n",
    "print(f\"f1 best model cross_val_score (0 most frequent): {BestModel_0mf_f1:.4f}\")\n",
    "print(f\"f1 best model cross_val_score (1 most frequent): {BestModel_1mf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Dummy_classifier</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LogisticRegression</th>\n",
       "      <th colspan=\"3\" halign=\"left\">SVC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LinearSVC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RandomForestClassifier</th>\n",
       "      <th colspan=\"3\" halign=\"left\">GradientBoostingClassifier</th>\n",
       "      <th>GridSearchCV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data_preparation</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>No_modified</th>\n",
       "      <th>SimpleImputer</th>\n",
       "      <th>DropNA</th>\n",
       "      <th>BestModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760718</td>\n",
       "      <td>0.850907</td>\n",
       "      <td>0.850682</td>\n",
       "      <td>0.846845</td>\n",
       "      <td>0.839974</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.835700</td>\n",
       "      <td>0.852914</td>\n",
       "      <td>0.851255</td>\n",
       "      <td>0.848503</td>\n",
       "      <td>0.852565</td>\n",
       "      <td>0.853303</td>\n",
       "      <td>0.848967</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.866590</td>\n",
       "      <td>0.862943</td>\n",
       "      <td>0.867573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_0_most_frequent</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655816</td>\n",
       "      <td>0.654437</td>\n",
       "      <td>0.660159</td>\n",
       "      <td>0.620083</td>\n",
       "      <td>0.616722</td>\n",
       "      <td>0.626712</td>\n",
       "      <td>0.657816</td>\n",
       "      <td>0.651865</td>\n",
       "      <td>0.661613</td>\n",
       "      <td>0.666582</td>\n",
       "      <td>0.668446</td>\n",
       "      <td>0.672592</td>\n",
       "      <td>0.686905</td>\n",
       "      <td>0.683188</td>\n",
       "      <td>0.687097</td>\n",
       "      <td>0.686874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_1_most_frequent</th>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.904843</td>\n",
       "      <td>0.904765</td>\n",
       "      <td>0.901146</td>\n",
       "      <td>0.898648</td>\n",
       "      <td>0.898483</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>0.905422</td>\n",
       "      <td>0.902403</td>\n",
       "      <td>0.904750</td>\n",
       "      <td>0.905036</td>\n",
       "      <td>0.901342</td>\n",
       "      <td>0.916026</td>\n",
       "      <td>0.915502</td>\n",
       "      <td>0.912252</td>\n",
       "      <td>0.916028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algorithm          Dummy_classifier LogisticRegression                \\\n",
       "Data_preparation        No_modified        No_modified SimpleImputer   \n",
       "accuracy                   0.760718           0.850907      0.850682   \n",
       "f1_0_most_frequent         0.000000           0.655816      0.654437   \n",
       "f1_1_most_frequent         0.864100           0.904843      0.904765   \n",
       "\n",
       "Algorithm                            SVC                           LinearSVC  \\\n",
       "Data_preparation      DropNA No_modified SimpleImputer    DropNA No_modified   \n",
       "accuracy            0.846845    0.839974      0.839503  0.835700    0.852914   \n",
       "f1_0_most_frequent  0.660159    0.620083      0.616722  0.626712    0.657816   \n",
       "f1_1_most_frequent  0.901146    0.898648      0.898483  0.894667    0.906322   \n",
       "\n",
       "Algorithm                                  RandomForestClassifier  \\\n",
       "Data_preparation   SimpleImputer    DropNA            No_modified   \n",
       "accuracy                0.851255  0.848503               0.852565   \n",
       "f1_0_most_frequent      0.651865  0.661613               0.666582   \n",
       "f1_1_most_frequent      0.905422  0.902403               0.904750   \n",
       "\n",
       "Algorithm                                  GradientBoostingClassifier  \\\n",
       "Data_preparation   SimpleImputer    DropNA                No_modified   \n",
       "accuracy                0.853303  0.848967                   0.867573   \n",
       "f1_0_most_frequent      0.668446  0.672592                   0.686905   \n",
       "f1_1_most_frequent      0.905036  0.901342                   0.916026   \n",
       "\n",
       "Algorithm                                  GridSearchCV  \n",
       "Data_preparation   SimpleImputer    DropNA    BestModel  \n",
       "accuracy                0.866590  0.862943     0.867573  \n",
       "f1_0_most_frequent      0.683188  0.687097     0.686874  \n",
       "f1_1_most_frequent      0.915502  0.912252     0.916028  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сведем все результаты в таблицу\n",
    "cross_val_score_result = pd.DataFrame(data = [[DummyCl_accuracy, LogReg_accuracy, LogReg_SimpImp_accuracy, LogReg_DropNA_accuracy, SVC_accuracy, SVC_SimpImp_accuracy, SVC_DropNA_accuracy, LinSVC_accuracy, LinSVC_SimpImp_accuracy, LinSVC_DropNA_accuracy, RandFrst_accuracy, RandFrst_SimpImp_accuracy, RandFrst_DropNA_accuracy, GradBst_accuracy, GradBst_SimpImp_accuracy, GradBst_DropNA_accuracy, BestModel_1mf_accuracy],\n",
    "                                              [DummyCl_0mf_f1,   LogReg_0mf_f1,   LogReg_SimpImp_0mf_f1,   LogReg_DropNA_0mf_f1,   SVC_0mf_f1,   SVC_SimpImp_0mf_f1,   SVC_DropNA_0mf_f1,   LinSVC_0mf_f1,   LinSVC_SimpImp_0mf_f1,   LinSVC_DropNA_0mf_f1, RandFrst_0mf_f1,   RandFrst_SimpImp_0mf_f1,   RandFrst_DropNA_0mf_f1,   GradBst_0mf_f1, GradBst_SimpImp_0mf_f1, GradBst_DropNA_0mf_f1, BestModel_0mf_f1],\n",
    "                                              [DummyCl_1mf_f1,   LogReg_1mf_f1,   LogReg_SimpImp_1mf_f1,   LogReg_DropNA_1mf_f1,   SVC_1mf_f1,   SVC_SimpImp_1mf_f1,   SVC_DropNA_1mf_f1,   LinSVC_1mf_f1,   LinSVC_SimpImp_1mf_f1,   LinSVC_DropNA_1mf_f1, RandFrst_1mf_f1,   RandFrst_SimpImp_1mf_f1,   RandFrst_DropNA_1mf_f1,   GradBst_1mf_f1, GradBst_SimpImp_1mf_f1, GradBst_DropNA_1mf_f1, BestModel_1mf_f1]],\n",
    "                                      index = ['accuracy', 'f1_0_most_frequent', 'f1_1_most_frequent'],\n",
    "                                      columns = pd.MultiIndex.from_tuples([('Dummy_classifier', 'No_modified'),\n",
    "                                                                           ('LogisticRegression', 'No_modified'), ('LogisticRegression', 'SimpleImputer'), ('LogisticRegression', 'DropNA'),\n",
    "                                                                           ('SVC', 'No_modified'), ('SVC', 'SimpleImputer'), ('SVC', 'DropNA'),\n",
    "                                                                           ('LinearSVC', 'No_modified'), ('LinearSVC', 'SimpleImputer'), ('LinearSVC', 'DropNA'),\n",
    "                                                                           ('RandomForestClassifier', 'No_modified'), ('RandomForestClassifier', 'SimpleImputer'), ('RandomForestClassifier', 'DropNA'),\n",
    "                                                                           ('GradientBoostingClassifier', 'No_modified'), ('GradientBoostingClassifier', 'SimpleImputer'), ('GradientBoostingClassifier', 'DropNA'),\n",
    "                                                                           ('GridSearchCV', 'BestModel'),\n",
    "                                                                           ],\n",
    "                                                                          names=['Algorithm', 'Data_preparation']))\n",
    "cross_val_score_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "- по cross_val_score метрики accuracy и f1 немного хуже, чем просто при расчете их по тестовой выборке (может, так совпали данные);\n",
    "- путем подбора параметров модели не удалось преодолеть значения метрик, полученных для градиентного бустинга без обработки пропушенных значений."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
